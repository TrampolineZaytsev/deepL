{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install pandas_ta --quiet"
      ],
      "metadata": {
        "id": "-05X4E1wbR9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "674c5c94-ffd5-499a-ef50-1bffabf94e16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/115.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pandas_ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "mm06V7JuWyHl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pandas_ta as ta\n",
        "import yfinance as yf\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras import Model\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Input, Dense, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "С помощью специальной библиотеки (yfinancd) стянем данные с биржи."
      ],
      "metadata": {
        "id": "uMfw8xqzt-Qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_date = dt.datetime(2018, 1, 1)\n",
        "\n",
        "end_date = dt.datetime.now( )\n",
        "\n",
        "data = yf.download('TON11419-USD', start=start_date, end=end_date)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "J0GctoPabD5W",
        "outputId": "94078f2c-d300-44c1-9de7-6ed4bbacdd71"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Open      High       Low     Close  Adj Close      Volume\n",
              "Date                                                                     \n",
              "2021-08-27  0.519893  0.687477  0.498175  0.686748   0.686748      573566\n",
              "2021-08-28  0.686766  0.691065  0.606474  0.640526   0.640526      250158\n",
              "2021-08-29  0.640724  0.648018  0.527709  0.548201   0.548201      188295\n",
              "2021-08-30  0.548234  0.915924  0.547050  0.868268   0.868268      763243\n",
              "2021-08-31  0.869410  1.132030  0.795093  1.034563   1.034563     1802341\n",
              "...              ...       ...       ...       ...        ...         ...\n",
              "2024-08-26  5.786217  5.815028  5.082398  5.115549   5.115549   991748884\n",
              "2024-08-27  5.115549  5.627440  5.115549  5.453750   5.453750   703687795\n",
              "2024-08-28  5.453750  5.887649  5.151222  5.523499   5.523499  1434235826\n",
              "2024-08-29  5.523499  5.640233  5.380773  5.452642   5.452642   363616609\n",
              "2024-08-30  5.453161  5.502014  5.285275  5.353930   5.353930   270361216\n",
              "\n",
              "[1100 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47e440f9-5e1f-4fb8-9bf5-ccaf3e807bf9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-08-27</th>\n",
              "      <td>0.519893</td>\n",
              "      <td>0.687477</td>\n",
              "      <td>0.498175</td>\n",
              "      <td>0.686748</td>\n",
              "      <td>0.686748</td>\n",
              "      <td>573566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-28</th>\n",
              "      <td>0.686766</td>\n",
              "      <td>0.691065</td>\n",
              "      <td>0.606474</td>\n",
              "      <td>0.640526</td>\n",
              "      <td>0.640526</td>\n",
              "      <td>250158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-29</th>\n",
              "      <td>0.640724</td>\n",
              "      <td>0.648018</td>\n",
              "      <td>0.527709</td>\n",
              "      <td>0.548201</td>\n",
              "      <td>0.548201</td>\n",
              "      <td>188295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-30</th>\n",
              "      <td>0.548234</td>\n",
              "      <td>0.915924</td>\n",
              "      <td>0.547050</td>\n",
              "      <td>0.868268</td>\n",
              "      <td>0.868268</td>\n",
              "      <td>763243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-08-31</th>\n",
              "      <td>0.869410</td>\n",
              "      <td>1.132030</td>\n",
              "      <td>0.795093</td>\n",
              "      <td>1.034563</td>\n",
              "      <td>1.034563</td>\n",
              "      <td>1802341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-26</th>\n",
              "      <td>5.786217</td>\n",
              "      <td>5.815028</td>\n",
              "      <td>5.082398</td>\n",
              "      <td>5.115549</td>\n",
              "      <td>5.115549</td>\n",
              "      <td>991748884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-27</th>\n",
              "      <td>5.115549</td>\n",
              "      <td>5.627440</td>\n",
              "      <td>5.115549</td>\n",
              "      <td>5.453750</td>\n",
              "      <td>5.453750</td>\n",
              "      <td>703687795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-28</th>\n",
              "      <td>5.453750</td>\n",
              "      <td>5.887649</td>\n",
              "      <td>5.151222</td>\n",
              "      <td>5.523499</td>\n",
              "      <td>5.523499</td>\n",
              "      <td>1434235826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-29</th>\n",
              "      <td>5.523499</td>\n",
              "      <td>5.640233</td>\n",
              "      <td>5.380773</td>\n",
              "      <td>5.452642</td>\n",
              "      <td>5.452642</td>\n",
              "      <td>363616609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-30</th>\n",
              "      <td>5.453161</td>\n",
              "      <td>5.502014</td>\n",
              "      <td>5.285275</td>\n",
              "      <td>5.353930</td>\n",
              "      <td>5.353930</td>\n",
              "      <td>270361216</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1100 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47e440f9-5e1f-4fb8-9bf5-ccaf3e807bf9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-47e440f9-5e1f-4fb8-9bf5-ccaf3e807bf9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-47e440f9-5e1f-4fb8-9bf5-ccaf3e807bf9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-82821118-7c70-4a5f-8eaf-4c55e80c8379\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-82821118-7c70-4a5f-8eaf-4c55e80c8379')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-82821118-7c70-4a5f-8eaf-4c55e80c8379 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1100,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2021-08-27 00:00:00\",\n        \"max\": \"2024-08-30 00:00:00\",\n        \"num_unique_values\": 1100,\n        \"samples\": [\n          \"2022-07-21 00:00:00\",\n          \"2023-07-16 00:00:00\",\n          \"2022-10-14 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7691154251401233,\n        \"min\": 0.5198929905891418,\n        \"max\": 8.177467346191406,\n        \"num_unique_values\": 1100,\n        \"samples\": [\n          0.9394540190696716,\n          1.3562339544296265,\n          1.2021520137786865\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.835797523552034,\n        \"min\": 0.6286600232124329,\n        \"max\": 8.23502254486084,\n        \"num_unique_values\": 1099,\n        \"samples\": [\n          2.4507930278778076,\n          7.720501899719238,\n          1.7402379512786865\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7106613750348543,\n        \"min\": 0.3906170129776001,\n        \"max\": 7.872790813446045,\n        \"num_unique_values\": 1100,\n        \"samples\": [\n          0.9185810089111328,\n          1.3500089645385742,\n          1.201259970664978\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7700620581534834,\n        \"min\": 0.5482010245323181,\n        \"max\": 8.177352905273438,\n        \"num_unique_values\": 1100,\n        \"samples\": [\n          0.9207689762115479,\n          1.3501520156860352,\n          1.2495659589767456\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adj Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7700620581534834,\n        \"min\": 0.5482010245323181,\n        \"max\": 8.177352905273438,\n        \"num_unique_values\": 1100,\n        \"samples\": [\n          0.9207689762115479,\n          1.3501520156860352,\n          1.2495659589767456\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 158544477,\n        \"min\": 53891,\n        \"max\": 1807572281,\n        \"num_unique_values\": 1100,\n        \"samples\": [\n          1929997,\n          6393962,\n          7450170\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавим технические индикаторы, такие как индекс относительной силы (rsi) и экспоненциально сглаженные скользящие средние для диапазона 20 и 50 точек (ema_20, ema_50)"
      ],
      "metadata": {
        "id": "GxCPlcWBuRMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['rsi'] = ta.rsi(data.Close, length=14)\n",
        "data ['ema_20'] = ta.ema(data.Close, length=20)\n",
        "data ['ema_50'] = ta.ema(data.Close, length=50)"
      ],
      "metadata": {
        "id": "k7Xxbh1EgA4n"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполним предобработку на очистку отсутсвующих значений и масштабирование данных"
      ],
      "metadata": {
        "id": "BTmcRg3gvdzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop NaN\n",
        "data = data.dropna(axis=0)\n",
        "data.isna().value_counts ()"
      ],
      "metadata": {
        "id": "2ZimCdkRe3Cm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "5b53a578-4e42-4a4d-a88e-d87963009a14"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Open   High   Low    Close  Adj Close  Volume  rsi    ema_20  ema_50\n",
              "False  False  False  False  False      False   False  False   False     1051\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>rsi</th>\n",
              "      <th>ema_20</th>\n",
              "      <th>ema_50</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>False</th>\n",
              "      <th>False</th>\n",
              "      <th>False</th>\n",
              "      <th>False</th>\n",
              "      <th>False</th>\n",
              "      <th>False</th>\n",
              "      <th>False</th>\n",
              "      <th>False</th>\n",
              "      <th>False</th>\n",
              "      <td>1051</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nCyV4M5dBbAN"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = data['Close']\n",
        "del data['Close']\n",
        "del data['Adj Close']\n",
        "X = data"
      ],
      "metadata": {
        "id": "z5i-qFIGWPGV"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "x_scaled = scaler.fit_transform(X)\n",
        "y_scaled = scaler.fit_transform(y.values.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "m92OUwQDzq24"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовим данные к обучению:"
      ],
      "metadata": {
        "id": "KTtQyUw_v2UK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#разобьем данные на тренировочные, валидационные и тестовые\n",
        "test_size = 0.3\n",
        "len_x = len(X)\n",
        "X_train = x_scaled[:int(len_x*(1-test_size)) ]\n",
        "y_train = y_scaled[:int(len_x*(1-test_size))]\n",
        "X_test = x_scaled[int(len_x*(1-test_size)):]\n",
        "y_test = y_scaled[int(len_x*(1-test_size)):]\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Nm7ehqIWz1br"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разобьем выборки по пакетам и \"временным\" окнам, а также разделяем тренировочные данные на обучающие и валидационные"
      ],
      "metadata": {
        "id": "G-82ThfswehO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_window(X_loc, y_loc):\n",
        "  window = 50\n",
        "  batch_size = 32\n",
        "  dataset_loc = keras.preprocessing.timeseries_dataset_from_array(\n",
        "    X_loc,\n",
        "    y_loc[window-1:], #сместим выходные данные, чтобы результатом предсказания было последний объект последовательности\n",
        "    sequence_length=window,\n",
        "    sampling_rate=1, #это смещение между данными в одном окне. 1 - идут подряд\n",
        "    batch_size=batch_size,\n",
        "  )\n",
        "  return dataset_loc"
      ],
      "metadata": {
        "id": "5y9b2dLTFIeE"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = split_window(X_train, y_train)\n",
        "\n",
        "dataset_val = split_window(X_valid, y_valid)\n",
        "\n",
        "\n",
        "for batch in dataset_train:\n",
        "   inputs, targets = batch\n",
        "   break\n"
      ],
      "metadata": {
        "id": "Ag6unJYYpsoy",
        "collapsed": true
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Построим модель"
      ],
      "metadata": {
        "id": "vefJ2aizgaOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
        "lstm_out =LSTM(32)(inputs)\n",
        "outputs = Dense(1)(lstm_out)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "9TYpJ-6010YY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "e480ad20-9e2f-4a6b-9255-18e909d27035"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m7\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m5,120\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,153\u001b[0m (20.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,153</span> (20.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,153\u001b[0m (20.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,153</span> (20.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим модель"
      ],
      "metadata": {
        "id": "He32HSb_gpiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"./best-model.keras\"\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=20, verbose=1)\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"./logs\")\n",
        "\n",
        "history = model.fit(\n",
        "    dataset_train,\n",
        "    validation_data=dataset_val,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    callbacks=[\n",
        "        checkpoint,\n",
        "        early_stopping,\n",
        "        tensorboard\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDl6kcIVzQY0",
        "outputId": "11ec0754-4bac-4aa9-bfd0-c4382168c32d"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0247 - mae: 0.1260\n",
            "Epoch 1: val_loss improved from inf to 0.00927, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0235 - mae: 0.1222 - val_loss: 0.0093 - val_mae: 0.0835\n",
            "Epoch 2/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0071 - mae: 0.0669\n",
            "Epoch 2: val_loss improved from 0.00927 to 0.00774, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0070 - mae: 0.0664 - val_loss: 0.0077 - val_mae: 0.0647\n",
            "Epoch 3/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0060 - mae: 0.0607\n",
            "Epoch 3: val_loss improved from 0.00774 to 0.00671, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0059 - mae: 0.0604 - val_loss: 0.0067 - val_mae: 0.0645\n",
            "Epoch 4/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0055 - mae: 0.0582\n",
            "Epoch 4: val_loss improved from 0.00671 to 0.00624, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0054 - mae: 0.0580 - val_loss: 0.0062 - val_mae: 0.0603\n",
            "Epoch 5/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0050 - mae: 0.0557\n",
            "Epoch 5: val_loss improved from 0.00624 to 0.00569, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0050 - mae: 0.0555 - val_loss: 0.0057 - val_mae: 0.0578\n",
            "Epoch 6/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0046 - mae: 0.0531\n",
            "Epoch 6: val_loss improved from 0.00569 to 0.00515, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0045 - mae: 0.0530 - val_loss: 0.0052 - val_mae: 0.0551\n",
            "Epoch 7/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0508\n",
            "Epoch 7: val_loss improved from 0.00515 to 0.00461, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0041 - mae: 0.0504 - val_loss: 0.0046 - val_mae: 0.0520\n",
            "Epoch 8/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0037 - mae: 0.0476\n",
            "Epoch 8: val_loss improved from 0.00461 to 0.00405, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0041 - val_mae: 0.0489\n",
            "Epoch 9/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0032 - mae: 0.0446\n",
            "Epoch 9: val_loss improved from 0.00405 to 0.00349, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0032 - mae: 0.0443 - val_loss: 0.0035 - val_mae: 0.0455\n",
            "Epoch 10/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0028 - mae: 0.0410\n",
            "Epoch 10: val_loss improved from 0.00349 to 0.00291, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0027 - mae: 0.0408 - val_loss: 0.0029 - val_mae: 0.0418\n",
            "Epoch 11/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0023 - mae: 0.0371\n",
            "Epoch 11: val_loss improved from 0.00291 to 0.00233, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0022 - mae: 0.0369 - val_loss: 0.0023 - val_mae: 0.0373\n",
            "Epoch 12/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0018 - mae: 0.0325\n",
            "Epoch 12: val_loss improved from 0.00233 to 0.00172, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0017 - mae: 0.0323 - val_loss: 0.0017 - val_mae: 0.0305\n",
            "Epoch 13/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0012 - mae: 0.0269\n",
            "Epoch 13: val_loss improved from 0.00172 to 0.00101, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0012 - mae: 0.0267 - val_loss: 0.0010 - val_mae: 0.0230\n",
            "Epoch 14/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.9603e-04 - mae: 0.0187\n",
            "Epoch 14: val_loss improved from 0.00101 to 0.00050, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 5.9005e-04 - mae: 0.0186 - val_loss: 5.0390e-04 - val_mae: 0.0139\n",
            "Epoch 15/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.5974e-04 - mae: 0.0122\n",
            "Epoch 15: val_loss improved from 0.00050 to 0.00038, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 2.5931e-04 - mae: 0.0122 - val_loss: 3.8058e-04 - val_mae: 0.0111\n",
            "Epoch 16/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.6269e-04 - mae: 0.0095\n",
            "Epoch 16: val_loss improved from 0.00038 to 0.00034, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1.6558e-04 - mae: 0.0096 - val_loss: 3.4168e-04 - val_mae: 0.0103\n",
            "Epoch 17/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1466e-04 - mae: 0.0077\n",
            "Epoch 17: val_loss improved from 0.00034 to 0.00034, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.1660e-04 - mae: 0.0078 - val_loss: 3.3757e-04 - val_mae: 0.0099\n",
            "Epoch 18/500\n",
            "\u001b[1m14/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9.4973e-05 - mae: 0.0070\n",
            "Epoch 18: val_loss did not improve from 0.00034\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.0004e-04 - mae: 0.0070 - val_loss: 3.4151e-04 - val_mae: 0.0097\n",
            "Epoch 19/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0021e-04 - mae: 0.0071\n",
            "Epoch 19: val_loss improved from 0.00034 to 0.00034, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0236e-04 - mae: 0.0071 - val_loss: 3.3649e-04 - val_mae: 0.0095\n",
            "Epoch 20/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9.9724e-05 - mae: 0.0070\n",
            "Epoch 20: val_loss improved from 0.00034 to 0.00033, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.0062e-04 - mae: 0.0070 - val_loss: 3.3198e-04 - val_mae: 0.0094\n",
            "Epoch 21/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.5418e-05 - mae: 0.0068\n",
            "Epoch 21: val_loss improved from 0.00033 to 0.00033, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 9.7225e-05 - mae: 0.0069 - val_loss: 3.3025e-04 - val_mae: 0.0093\n",
            "Epoch 22/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9.3123e-05 - mae: 0.0068\n",
            "Epoch 22: val_loss improved from 0.00033 to 0.00033, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 9.5803e-05 - mae: 0.0068 - val_loss: 3.2855e-04 - val_mae: 0.0092\n",
            "Epoch 23/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.3365e-05 - mae: 0.0067\n",
            "Epoch 23: val_loss improved from 0.00033 to 0.00033, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.5019e-05 - mae: 0.0068 - val_loss: 3.2616e-04 - val_mae: 0.0092\n",
            "Epoch 24/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9.1527e-05 - mae: 0.0067\n",
            "Epoch 24: val_loss improved from 0.00033 to 0.00032, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 9.3975e-05 - mae: 0.0067 - val_loss: 3.2364e-04 - val_mae: 0.0091\n",
            "Epoch 25/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9.2122e-05 - mae: 0.0067\n",
            "Epoch 25: val_loss improved from 0.00032 to 0.00032, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 9.2839e-05 - mae: 0.0067 - val_loss: 3.2120e-04 - val_mae: 0.0090\n",
            "Epoch 26/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.9514e-05 - mae: 0.0066\n",
            "Epoch 26: val_loss improved from 0.00032 to 0.00032, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 9.1786e-05 - mae: 0.0066 - val_loss: 3.1880e-04 - val_mae: 0.0090\n",
            "Epoch 27/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.8619e-05 - mae: 0.0066\n",
            "Epoch 27: val_loss improved from 0.00032 to 0.00032, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 9.0813e-05 - mae: 0.0066 - val_loss: 3.1640e-04 - val_mae: 0.0089\n",
            "Epoch 28/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.8516e-05 - mae: 0.0065\n",
            "Epoch 28: val_loss improved from 0.00032 to 0.00031, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 8.9885e-05 - mae: 0.0066 - val_loss: 3.1401e-04 - val_mae: 0.0089\n",
            "Epoch 29/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.6948e-05 - mae: 0.0065\n",
            "Epoch 29: val_loss improved from 0.00031 to 0.00031, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 8.8996e-05 - mae: 0.0065 - val_loss: 3.1165e-04 - val_mae: 0.0088\n",
            "Epoch 30/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.6873e-05 - mae: 0.0065\n",
            "Epoch 30: val_loss improved from 0.00031 to 0.00031, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.8153e-05 - mae: 0.0065 - val_loss: 3.0934e-04 - val_mae: 0.0088\n",
            "Epoch 31/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.5443e-05 - mae: 0.0064\n",
            "Epoch 31: val_loss improved from 0.00031 to 0.00031, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 8.7357e-05 - mae: 0.0064 - val_loss: 3.0708e-04 - val_mae: 0.0087\n",
            "Epoch 32/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.4759e-05 - mae: 0.0064\n",
            "Epoch 32: val_loss improved from 0.00031 to 0.00030, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 8.6608e-05 - mae: 0.0064 - val_loss: 3.0486e-04 - val_mae: 0.0087\n",
            "Epoch 33/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 8.5359e-05 - mae: 0.0064\n",
            "Epoch 33: val_loss improved from 0.00030 to 0.00030, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 8.5904e-05 - mae: 0.0064 - val_loss: 3.0270e-04 - val_mae: 0.0086\n",
            "Epoch 34/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.4714e-05 - mae: 0.0063\n",
            "Epoch 34: val_loss improved from 0.00030 to 0.00030, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 8.5241e-05 - mae: 0.0063 - val_loss: 3.0057e-04 - val_mae: 0.0086\n",
            "Epoch 35/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 8.2954e-05 - mae: 0.0063\n",
            "Epoch 35: val_loss improved from 0.00030 to 0.00030, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 8.4618e-05 - mae: 0.0063 - val_loss: 2.9850e-04 - val_mae: 0.0085\n",
            "Epoch 36/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 8.3543e-05 - mae: 0.0063\n",
            "Epoch 36: val_loss improved from 0.00030 to 0.00030, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 8.4034e-05 - mae: 0.0063 - val_loss: 2.9648e-04 - val_mae: 0.0085\n",
            "Epoch 37/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 8.2479e-05 - mae: 0.0062\n",
            "Epoch 37: val_loss improved from 0.00030 to 0.00029, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 8.3486e-05 - mae: 0.0063 - val_loss: 2.9450e-04 - val_mae: 0.0085\n",
            "Epoch 38/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 8.2516e-05 - mae: 0.0062\n",
            "Epoch 38: val_loss improved from 0.00029 to 0.00029, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 8.2973e-05 - mae: 0.0062 - val_loss: 2.9257e-04 - val_mae: 0.0084\n",
            "Epoch 39/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.1556e-05 - mae: 0.0062\n",
            "Epoch 39: val_loss improved from 0.00029 to 0.00029, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 8.2493e-05 - mae: 0.0062 - val_loss: 2.9068e-04 - val_mae: 0.0084\n",
            "Epoch 40/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.1142e-05 - mae: 0.0062\n",
            "Epoch 40: val_loss improved from 0.00029 to 0.00029, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 8.2044e-05 - mae: 0.0062 - val_loss: 2.8884e-04 - val_mae: 0.0084\n",
            "Epoch 41/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.0756e-05 - mae: 0.0062\n",
            "Epoch 41: val_loss improved from 0.00029 to 0.00029, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 8.1623e-05 - mae: 0.0062 - val_loss: 2.8704e-04 - val_mae: 0.0084\n",
            "Epoch 42/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 8.0397e-05 - mae: 0.0061\n",
            "Epoch 42: val_loss improved from 0.00029 to 0.00029, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 8.1231e-05 - mae: 0.0062 - val_loss: 2.8529e-04 - val_mae: 0.0083\n",
            "Epoch 43/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 8.0487e-05 - mae: 0.0061\n",
            "Epoch 43: val_loss improved from 0.00029 to 0.00028, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 8.0865e-05 - mae: 0.0061 - val_loss: 2.8358e-04 - val_mae: 0.0083\n",
            "Epoch 44/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.9754e-05 - mae: 0.0061\n",
            "Epoch 44: val_loss improved from 0.00028 to 0.00028, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 8.0523e-05 - mae: 0.0061 - val_loss: 2.8191e-04 - val_mae: 0.0083\n",
            "Epoch 45/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.9095e-05 - mae: 0.0061\n",
            "Epoch 45: val_loss improved from 0.00028 to 0.00028, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 8.0203e-05 - mae: 0.0061 - val_loss: 2.8028e-04 - val_mae: 0.0082\n",
            "Epoch 46/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.9199e-05 - mae: 0.0061\n",
            "Epoch 46: val_loss improved from 0.00028 to 0.00028, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.9904e-05 - mae: 0.0061 - val_loss: 2.7869e-04 - val_mae: 0.0082\n",
            "Epoch 47/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.8620e-05 - mae: 0.0061\n",
            "Epoch 47: val_loss improved from 0.00028 to 0.00028, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.9626e-05 - mae: 0.0061 - val_loss: 2.7714e-04 - val_mae: 0.0082\n",
            "Epoch 48/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.8723e-05 - mae: 0.0060\n",
            "Epoch 48: val_loss improved from 0.00028 to 0.00028, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.9366e-05 - mae: 0.0061 - val_loss: 2.7563e-04 - val_mae: 0.0082\n",
            "Epoch 49/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.8510e-05 - mae: 0.0060\n",
            "Epoch 49: val_loss improved from 0.00028 to 0.00027, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.9123e-05 - mae: 0.0061 - val_loss: 2.7415e-04 - val_mae: 0.0082\n",
            "Epoch 50/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.8622e-05 - mae: 0.0060\n",
            "Epoch 50: val_loss improved from 0.00027 to 0.00027, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.8896e-05 - mae: 0.0060 - val_loss: 2.7271e-04 - val_mae: 0.0081\n",
            "Epoch 51/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.8130e-05 - mae: 0.0060\n",
            "Epoch 51: val_loss improved from 0.00027 to 0.00027, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 7.8684e-05 - mae: 0.0060 - val_loss: 2.7131e-04 - val_mae: 0.0081\n",
            "Epoch 52/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.8238e-05 - mae: 0.0060\n",
            "Epoch 52: val_loss improved from 0.00027 to 0.00027, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 7.8486e-05 - mae: 0.0060 - val_loss: 2.6994e-04 - val_mae: 0.0081\n",
            "Epoch 53/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.8066e-05 - mae: 0.0060\n",
            "Epoch 53: val_loss improved from 0.00027 to 0.00027, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.8300e-05 - mae: 0.0060 - val_loss: 2.6860e-04 - val_mae: 0.0081\n",
            "Epoch 54/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.7657e-05 - mae: 0.0060\n",
            "Epoch 54: val_loss improved from 0.00027 to 0.00027, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.8126e-05 - mae: 0.0060 - val_loss: 2.6730e-04 - val_mae: 0.0080\n",
            "Epoch 55/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 7.7521e-05 - mae: 0.0060\n",
            "Epoch 55: val_loss improved from 0.00027 to 0.00027, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 7.7963e-05 - mae: 0.0060 - val_loss: 2.6602e-04 - val_mae: 0.0080\n",
            "Epoch 56/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.7394e-05 - mae: 0.0060\n",
            "Epoch 56: val_loss improved from 0.00027 to 0.00026, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 7.7809e-05 - mae: 0.0060 - val_loss: 2.6478e-04 - val_mae: 0.0080\n",
            "Epoch 57/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.7482e-05 - mae: 0.0060\n",
            "Epoch 57: val_loss improved from 0.00026 to 0.00026, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 7.7665e-05 - mae: 0.0060 - val_loss: 2.6357e-04 - val_mae: 0.0080\n",
            "Epoch 58/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.7166e-05 - mae: 0.0060\n",
            "Epoch 58: val_loss improved from 0.00026 to 0.00026, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.7529e-05 - mae: 0.0060 - val_loss: 2.6239e-04 - val_mae: 0.0080\n",
            "Epoch 59/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.7063e-05 - mae: 0.0060\n",
            "Epoch 59: val_loss improved from 0.00026 to 0.00026, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 7.7401e-05 - mae: 0.0060 - val_loss: 2.6124e-04 - val_mae: 0.0079\n",
            "Epoch 60/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.6861e-05 - mae: 0.0060\n",
            "Epoch 60: val_loss improved from 0.00026 to 0.00026, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.7279e-05 - mae: 0.0060 - val_loss: 2.6011e-04 - val_mae: 0.0079\n",
            "Epoch 61/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.7029e-05 - mae: 0.0060\n",
            "Epoch 61: val_loss improved from 0.00026 to 0.00026, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 7.7164e-05 - mae: 0.0060 - val_loss: 2.5902e-04 - val_mae: 0.0079\n",
            "Epoch 62/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.6791e-05 - mae: 0.0059\n",
            "Epoch 62: val_loss improved from 0.00026 to 0.00026, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.7055e-05 - mae: 0.0060 - val_loss: 2.5795e-04 - val_mae: 0.0079\n",
            "Epoch 63/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.6651e-05 - mae: 0.0059\n",
            "Epoch 63: val_loss improved from 0.00026 to 0.00026, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.6951e-05 - mae: 0.0059 - val_loss: 2.5690e-04 - val_mae: 0.0079\n",
            "Epoch 64/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.6635e-05 - mae: 0.0059\n",
            "Epoch 64: val_loss improved from 0.00026 to 0.00026, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.6851e-05 - mae: 0.0059 - val_loss: 2.5588e-04 - val_mae: 0.0079\n",
            "Epoch 65/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.6531e-05 - mae: 0.0059\n",
            "Epoch 65: val_loss improved from 0.00026 to 0.00025, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.6757e-05 - mae: 0.0059 - val_loss: 2.5488e-04 - val_mae: 0.0078\n",
            "Epoch 66/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.6494e-05 - mae: 0.0059\n",
            "Epoch 66: val_loss improved from 0.00025 to 0.00025, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.6666e-05 - mae: 0.0059 - val_loss: 2.5390e-04 - val_mae: 0.0078\n",
            "Epoch 67/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.6429e-05 - mae: 0.0059\n",
            "Epoch 67: val_loss improved from 0.00025 to 0.00025, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.6578e-05 - mae: 0.0059 - val_loss: 2.5295e-04 - val_mae: 0.0078\n",
            "Epoch 68/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.6366e-05 - mae: 0.0059\n",
            "Epoch 68: val_loss improved from 0.00025 to 0.00025, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.6494e-05 - mae: 0.0059 - val_loss: 2.5202e-04 - val_mae: 0.0078\n",
            "Epoch 69/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.6326e-05 - mae: 0.0059\n",
            "Epoch 69: val_loss improved from 0.00025 to 0.00025, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.6413e-05 - mae: 0.0059 - val_loss: 2.5111e-04 - val_mae: 0.0078\n",
            "Epoch 70/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.6280e-05 - mae: 0.0059\n",
            "Epoch 70: val_loss improved from 0.00025 to 0.00025, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 7.6334e-05 - mae: 0.0059 - val_loss: 2.5022e-04 - val_mae: 0.0078\n",
            "Epoch 71/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.6226e-05 - mae: 0.0059\n",
            "Epoch 71: val_loss improved from 0.00025 to 0.00025, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 7.6257e-05 - mae: 0.0059 - val_loss: 2.4934e-04 - val_mae: 0.0077\n",
            "Epoch 72/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.6135e-05 - mae: 0.0059\n",
            "Epoch 72: val_loss improved from 0.00025 to 0.00025, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 7.6182e-05 - mae: 0.0059 - val_loss: 2.4849e-04 - val_mae: 0.0077\n",
            "Epoch 73/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.6150e-05 - mae: 0.0059\n",
            "Epoch 73: val_loss improved from 0.00025 to 0.00025, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 7.6109e-05 - mae: 0.0059 - val_loss: 2.4765e-04 - val_mae: 0.0077\n",
            "Epoch 74/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.6029e-05 - mae: 0.0059\n",
            "Epoch 74: val_loss improved from 0.00025 to 0.00025, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.6038e-05 - mae: 0.0059 - val_loss: 2.4683e-04 - val_mae: 0.0077\n",
            "Epoch 75/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.6067e-05 - mae: 0.0059\n",
            "Epoch 75: val_loss improved from 0.00025 to 0.00025, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.5967e-05 - mae: 0.0059 - val_loss: 2.4603e-04 - val_mae: 0.0077\n",
            "Epoch 76/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.5911e-05 - mae: 0.0059\n",
            "Epoch 76: val_loss improved from 0.00025 to 0.00025, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 7.5898e-05 - mae: 0.0059 - val_loss: 2.4524e-04 - val_mae: 0.0077\n",
            "Epoch 77/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 7.5851e-05 - mae: 0.0059\n",
            "Epoch 77: val_loss improved from 0.00025 to 0.00024, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 7.5830e-05 - mae: 0.0059 - val_loss: 2.4447e-04 - val_mae: 0.0077\n",
            "Epoch 78/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.5792e-05 - mae: 0.0059\n",
            "Epoch 78: val_loss improved from 0.00024 to 0.00024, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 7.5763e-05 - mae: 0.0059 - val_loss: 2.4371e-04 - val_mae: 0.0077\n",
            "Epoch 79/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 7.5733e-05 - mae: 0.0059\n",
            "Epoch 79: val_loss improved from 0.00024 to 0.00024, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 7.5696e-05 - mae: 0.0059 - val_loss: 2.4297e-04 - val_mae: 0.0076\n",
            "Epoch 80/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.5865e-05 - mae: 0.0058\n",
            "Epoch 80: val_loss improved from 0.00024 to 0.00024, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.5629e-05 - mae: 0.0058 - val_loss: 2.4224e-04 - val_mae: 0.0076\n",
            "Epoch 81/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.5674e-05 - mae: 0.0058\n",
            "Epoch 81: val_loss improved from 0.00024 to 0.00024, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.5563e-05 - mae: 0.0058 - val_loss: 2.4152e-04 - val_mae: 0.0076\n",
            "Epoch 82/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.5557e-05 - mae: 0.0058\n",
            "Epoch 82: val_loss improved from 0.00024 to 0.00024, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 7.5498e-05 - mae: 0.0058 - val_loss: 2.4081e-04 - val_mae: 0.0076\n",
            "Epoch 83/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.5499e-05 - mae: 0.0058\n",
            "Epoch 83: val_loss improved from 0.00024 to 0.00024, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 7.5432e-05 - mae: 0.0058 - val_loss: 2.4012e-04 - val_mae: 0.0076\n",
            "Epoch 84/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.5440e-05 - mae: 0.0058\n",
            "Epoch 84: val_loss improved from 0.00024 to 0.00024, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 7.5367e-05 - mae: 0.0058 - val_loss: 2.3943e-04 - val_mae: 0.0076\n",
            "Epoch 85/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.5472e-05 - mae: 0.0058\n",
            "Epoch 85: val_loss improved from 0.00024 to 0.00024, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 7.5301e-05 - mae: 0.0058 - val_loss: 2.3876e-04 - val_mae: 0.0076\n",
            "Epoch 86/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.5322e-05 - mae: 0.0058\n",
            "Epoch 86: val_loss improved from 0.00024 to 0.00024, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.5235e-05 - mae: 0.0058 - val_loss: 2.3810e-04 - val_mae: 0.0076\n",
            "Epoch 87/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.5263e-05 - mae: 0.0058\n",
            "Epoch 87: val_loss improved from 0.00024 to 0.00024, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 7.5170e-05 - mae: 0.0058 - val_loss: 2.3744e-04 - val_mae: 0.0075\n",
            "Epoch 88/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.5203e-05 - mae: 0.0058\n",
            "Epoch 88: val_loss improved from 0.00024 to 0.00024, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 7.5104e-05 - mae: 0.0058 - val_loss: 2.3680e-04 - val_mae: 0.0075\n",
            "Epoch 89/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.5262e-05 - mae: 0.0058\n",
            "Epoch 89: val_loss improved from 0.00024 to 0.00024, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 7.5037e-05 - mae: 0.0058 - val_loss: 2.3616e-04 - val_mae: 0.0075\n",
            "Epoch 90/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.5208e-05 - mae: 0.0058\n",
            "Epoch 90: val_loss improved from 0.00024 to 0.00024, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 7.4971e-05 - mae: 0.0058 - val_loss: 2.3554e-04 - val_mae: 0.0075\n",
            "Epoch 91/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.5021e-05 - mae: 0.0058\n",
            "Epoch 91: val_loss improved from 0.00024 to 0.00023, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 7.4904e-05 - mae: 0.0058 - val_loss: 2.3492e-04 - val_mae: 0.0075\n",
            "Epoch 92/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.4960e-05 - mae: 0.0058\n",
            "Epoch 92: val_loss improved from 0.00023 to 0.00023, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.4837e-05 - mae: 0.0058 - val_loss: 2.3431e-04 - val_mae: 0.0075\n",
            "Epoch 93/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.4898e-05 - mae: 0.0058\n",
            "Epoch 93: val_loss improved from 0.00023 to 0.00023, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 7.4769e-05 - mae: 0.0058 - val_loss: 2.3370e-04 - val_mae: 0.0075\n",
            "Epoch 94/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.4985e-05 - mae: 0.0058\n",
            "Epoch 94: val_loss improved from 0.00023 to 0.00023, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 7.4701e-05 - mae: 0.0058 - val_loss: 2.3310e-04 - val_mae: 0.0075\n",
            "Epoch 95/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.5185e-05 - mae: 0.0058\n",
            "Epoch 95: val_loss improved from 0.00023 to 0.00023, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.4632e-05 - mae: 0.0058 - val_loss: 2.3251e-04 - val_mae: 0.0075\n",
            "Epoch 96/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.5133e-05 - mae: 0.0058\n",
            "Epoch 96: val_loss improved from 0.00023 to 0.00023, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 7.4563e-05 - mae: 0.0058 - val_loss: 2.3193e-04 - val_mae: 0.0075\n",
            "Epoch 97/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 7.4811e-05 - mae: 0.0058\n",
            "Epoch 97: val_loss improved from 0.00023 to 0.00023, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 7.4493e-05 - mae: 0.0058 - val_loss: 2.3135e-04 - val_mae: 0.0074\n",
            "Epoch 98/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.4751e-05 - mae: 0.0057\n",
            "Epoch 98: val_loss improved from 0.00023 to 0.00023, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 7.4423e-05 - mae: 0.0057 - val_loss: 2.3078e-04 - val_mae: 0.0074\n",
            "Epoch 99/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 7.4690e-05 - mae: 0.0057\n",
            "Epoch 99: val_loss improved from 0.00023 to 0.00023, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 7.4352e-05 - mae: 0.0057 - val_loss: 2.3021e-04 - val_mae: 0.0074\n",
            "Epoch 100/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 7.4445e-05 - mae: 0.0057\n",
            "Epoch 100: val_loss improved from 0.00023 to 0.00023, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 7.4281e-05 - mae: 0.0057 - val_loss: 2.2965e-04 - val_mae: 0.0074\n",
            "Epoch 101/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.4859e-05 - mae: 0.0057\n",
            "Epoch 101: val_loss improved from 0.00023 to 0.00023, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.4209e-05 - mae: 0.0057 - val_loss: 2.2910e-04 - val_mae: 0.0074\n",
            "Epoch 102/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.4801e-05 - mae: 0.0057\n",
            "Epoch 102: val_loss improved from 0.00023 to 0.00023, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 7.4136e-05 - mae: 0.0057 - val_loss: 2.2854e-04 - val_mae: 0.0074\n",
            "Epoch 103/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.4742e-05 - mae: 0.0057\n",
            "Epoch 103: val_loss improved from 0.00023 to 0.00023, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.4063e-05 - mae: 0.0057 - val_loss: 2.2800e-04 - val_mae: 0.0074\n",
            "Epoch 104/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.4683e-05 - mae: 0.0057\n",
            "Epoch 104: val_loss improved from 0.00023 to 0.00023, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.3989e-05 - mae: 0.0057 - val_loss: 2.2745e-04 - val_mae: 0.0074\n",
            "Epoch 105/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.4310e-05 - mae: 0.0057\n",
            "Epoch 105: val_loss improved from 0.00023 to 0.00023, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.3915e-05 - mae: 0.0057 - val_loss: 2.2692e-04 - val_mae: 0.0074\n",
            "Epoch 106/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.4030e-05 - mae: 0.0057\n",
            "Epoch 106: val_loss improved from 0.00023 to 0.00023, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.3840e-05 - mae: 0.0057 - val_loss: 2.2638e-04 - val_mae: 0.0074\n",
            "Epoch 107/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.3959e-05 - mae: 0.0057\n",
            "Epoch 107: val_loss improved from 0.00023 to 0.00023, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.3765e-05 - mae: 0.0057 - val_loss: 2.2585e-04 - val_mae: 0.0074\n",
            "Epoch 108/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.4436e-05 - mae: 0.0057\n",
            "Epoch 108: val_loss improved from 0.00023 to 0.00023, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 7.3689e-05 - mae: 0.0057 - val_loss: 2.2532e-04 - val_mae: 0.0073\n",
            "Epoch 109/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.4041e-05 - mae: 0.0057\n",
            "Epoch 109: val_loss improved from 0.00023 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.3612e-05 - mae: 0.0057 - val_loss: 2.2480e-04 - val_mae: 0.0073\n",
            "Epoch 110/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.3972e-05 - mae: 0.0057\n",
            "Epoch 110: val_loss improved from 0.00022 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.3535e-05 - mae: 0.0057 - val_loss: 2.2428e-04 - val_mae: 0.0073\n",
            "Epoch 111/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.4242e-05 - mae: 0.0057\n",
            "Epoch 111: val_loss improved from 0.00022 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.3458e-05 - mae: 0.0057 - val_loss: 2.2376e-04 - val_mae: 0.0073\n",
            "Epoch 112/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.3593e-05 - mae: 0.0057\n",
            "Epoch 112: val_loss improved from 0.00022 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.3380e-05 - mae: 0.0057 - val_loss: 2.2324e-04 - val_mae: 0.0073\n",
            "Epoch 113/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.3518e-05 - mae: 0.0057\n",
            "Epoch 113: val_loss improved from 0.00022 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.3301e-05 - mae: 0.0057 - val_loss: 2.2273e-04 - val_mae: 0.0073\n",
            "Epoch 114/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.3689e-05 - mae: 0.0057\n",
            "Epoch 114: val_loss improved from 0.00022 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.3222e-05 - mae: 0.0057 - val_loss: 2.2222e-04 - val_mae: 0.0073\n",
            "Epoch 115/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.3617e-05 - mae: 0.0057\n",
            "Epoch 115: val_loss improved from 0.00022 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.3142e-05 - mae: 0.0057 - val_loss: 2.2171e-04 - val_mae: 0.0073\n",
            "Epoch 116/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.3543e-05 - mae: 0.0057\n",
            "Epoch 116: val_loss improved from 0.00022 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.3062e-05 - mae: 0.0057 - val_loss: 2.2121e-04 - val_mae: 0.0073\n",
            "Epoch 117/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.3470e-05 - mae: 0.0057\n",
            "Epoch 117: val_loss improved from 0.00022 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.2981e-05 - mae: 0.0057 - val_loss: 2.2071e-04 - val_mae: 0.0073\n",
            "Epoch 118/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.3133e-05 - mae: 0.0057\n",
            "Epoch 118: val_loss improved from 0.00022 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 7.2900e-05 - mae: 0.0056 - val_loss: 2.2021e-04 - val_mae: 0.0073\n",
            "Epoch 119/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.3054e-05 - mae: 0.0056\n",
            "Epoch 119: val_loss improved from 0.00022 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 7.2818e-05 - mae: 0.0056 - val_loss: 2.1971e-04 - val_mae: 0.0073\n",
            "Epoch 120/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 7.3244e-05 - mae: 0.0056\n",
            "Epoch 120: val_loss improved from 0.00022 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 7.2736e-05 - mae: 0.0056 - val_loss: 2.1921e-04 - val_mae: 0.0072\n",
            "Epoch 121/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 7.3546e-05 - mae: 0.0056\n",
            "Epoch 121: val_loss improved from 0.00022 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 7.2654e-05 - mae: 0.0056 - val_loss: 2.1872e-04 - val_mae: 0.0072\n",
            "Epoch 122/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.3092e-05 - mae: 0.0056\n",
            "Epoch 122: val_loss improved from 0.00022 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.2570e-05 - mae: 0.0056 - val_loss: 2.1823e-04 - val_mae: 0.0072\n",
            "Epoch 123/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.3398e-05 - mae: 0.0056\n",
            "Epoch 123: val_loss improved from 0.00022 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.2487e-05 - mae: 0.0056 - val_loss: 2.1774e-04 - val_mae: 0.0072\n",
            "Epoch 124/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.2937e-05 - mae: 0.0056\n",
            "Epoch 124: val_loss improved from 0.00022 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 7.2403e-05 - mae: 0.0056 - val_loss: 2.1725e-04 - val_mae: 0.0072\n",
            "Epoch 125/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.2572e-05 - mae: 0.0056\n",
            "Epoch 125: val_loss improved from 0.00022 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.2318e-05 - mae: 0.0056 - val_loss: 2.1676e-04 - val_mae: 0.0072\n",
            "Epoch 126/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.2490e-05 - mae: 0.0056\n",
            "Epoch 126: val_loss improved from 0.00022 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.2234e-05 - mae: 0.0056 - val_loss: 2.1628e-04 - val_mae: 0.0072\n",
            "Epoch 127/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.3097e-05 - mae: 0.0056\n",
            "Epoch 127: val_loss improved from 0.00022 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.2148e-05 - mae: 0.0056 - val_loss: 2.1579e-04 - val_mae: 0.0072\n",
            "Epoch 128/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.2325e-05 - mae: 0.0056\n",
            "Epoch 128: val_loss improved from 0.00022 to 0.00022, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 7.2063e-05 - mae: 0.0056 - val_loss: 2.1531e-04 - val_mae: 0.0072\n",
            "Epoch 129/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.2943e-05 - mae: 0.0056\n",
            "Epoch 129: val_loss improved from 0.00022 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 7.1977e-05 - mae: 0.0056 - val_loss: 2.1483e-04 - val_mae: 0.0072\n",
            "Epoch 130/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.2865e-05 - mae: 0.0056\n",
            "Epoch 130: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 7.1891e-05 - mae: 0.0056 - val_loss: 2.1435e-04 - val_mae: 0.0072\n",
            "Epoch 131/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.2787e-05 - mae: 0.0056\n",
            "Epoch 131: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.1804e-05 - mae: 0.0056 - val_loss: 2.1387e-04 - val_mae: 0.0072\n",
            "Epoch 132/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.1990e-05 - mae: 0.0056\n",
            "Epoch 132: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 7.1717e-05 - mae: 0.0056 - val_loss: 2.1340e-04 - val_mae: 0.0072\n",
            "Epoch 133/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.2629e-05 - mae: 0.0056\n",
            "Epoch 133: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 7.1630e-05 - mae: 0.0056 - val_loss: 2.1292e-04 - val_mae: 0.0071\n",
            "Epoch 134/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.2133e-05 - mae: 0.0056\n",
            "Epoch 134: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.1543e-05 - mae: 0.0056 - val_loss: 2.1245e-04 - val_mae: 0.0071\n",
            "Epoch 135/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.1735e-05 - mae: 0.0056\n",
            "Epoch 135: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 7.1455e-05 - mae: 0.0056 - val_loss: 2.1197e-04 - val_mae: 0.0071\n",
            "Epoch 136/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.1967e-05 - mae: 0.0056\n",
            "Epoch 136: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.1367e-05 - mae: 0.0056 - val_loss: 2.1150e-04 - val_mae: 0.0071\n",
            "Epoch 137/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.1883e-05 - mae: 0.0056\n",
            "Epoch 137: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.1278e-05 - mae: 0.0056 - val_loss: 2.1103e-04 - val_mae: 0.0071\n",
            "Epoch 138/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.1477e-05 - mae: 0.0056\n",
            "Epoch 138: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.1189e-05 - mae: 0.0055 - val_loss: 2.1056e-04 - val_mae: 0.0071\n",
            "Epoch 139/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 7.2146e-05 - mae: 0.0056\n",
            "Epoch 139: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 7.1100e-05 - mae: 0.0055 - val_loss: 2.1009e-04 - val_mae: 0.0071\n",
            "Epoch 140/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 7.1631e-05 - mae: 0.0055\n",
            "Epoch 140: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 7.1011e-05 - mae: 0.0055 - val_loss: 2.0962e-04 - val_mae: 0.0071\n",
            "Epoch 141/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 7.1547e-05 - mae: 0.0055\n",
            "Epoch 141: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 7.0922e-05 - mae: 0.0055 - val_loss: 2.0916e-04 - val_mae: 0.0071\n",
            "Epoch 142/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.1899e-05 - mae: 0.0055\n",
            "Epoch 142: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.0832e-05 - mae: 0.0055 - val_loss: 2.0869e-04 - val_mae: 0.0071\n",
            "Epoch 143/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.1816e-05 - mae: 0.0055\n",
            "Epoch 143: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.0742e-05 - mae: 0.0055 - val_loss: 2.0823e-04 - val_mae: 0.0071\n",
            "Epoch 144/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.0953e-05 - mae: 0.0055\n",
            "Epoch 144: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.0652e-05 - mae: 0.0055 - val_loss: 2.0777e-04 - val_mae: 0.0071\n",
            "Epoch 145/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.0864e-05 - mae: 0.0055\n",
            "Epoch 145: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.0561e-05 - mae: 0.0055 - val_loss: 2.0730e-04 - val_mae: 0.0071\n",
            "Epoch 146/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.0776e-05 - mae: 0.0055\n",
            "Epoch 146: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.0471e-05 - mae: 0.0055 - val_loss: 2.0684e-04 - val_mae: 0.0070\n",
            "Epoch 147/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.1481e-05 - mae: 0.0055\n",
            "Epoch 147: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.0380e-05 - mae: 0.0055 - val_loss: 2.0638e-04 - val_mae: 0.0070\n",
            "Epoch 148/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.0598e-05 - mae: 0.0055\n",
            "Epoch 148: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 7.0289e-05 - mae: 0.0055 - val_loss: 2.0592e-04 - val_mae: 0.0070\n",
            "Epoch 149/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.0509e-05 - mae: 0.0055\n",
            "Epoch 149: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.0197e-05 - mae: 0.0055 - val_loss: 2.0546e-04 - val_mae: 0.0070\n",
            "Epoch 150/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.1227e-05 - mae: 0.0055\n",
            "Epoch 150: val_loss improved from 0.00021 to 0.00021, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 7.0106e-05 - mae: 0.0055 - val_loss: 2.0501e-04 - val_mae: 0.0070\n",
            "Epoch 151/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.1142e-05 - mae: 0.0055\n",
            "Epoch 151: val_loss improved from 0.00021 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 7.0015e-05 - mae: 0.0055 - val_loss: 2.0455e-04 - val_mae: 0.0070\n",
            "Epoch 152/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.0597e-05 - mae: 0.0055\n",
            "Epoch 152: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 6.9923e-05 - mae: 0.0055 - val_loss: 2.0409e-04 - val_mae: 0.0070\n",
            "Epoch 153/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.0971e-05 - mae: 0.0055\n",
            "Epoch 153: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.9831e-05 - mae: 0.0055 - val_loss: 2.0364e-04 - val_mae: 0.0070\n",
            "Epoch 154/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.0885e-05 - mae: 0.0055\n",
            "Epoch 154: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.9739e-05 - mae: 0.0055 - val_loss: 2.0318e-04 - val_mae: 0.0070\n",
            "Epoch 155/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.9969e-05 - mae: 0.0055\n",
            "Epoch 155: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.9646e-05 - mae: 0.0055 - val_loss: 2.0273e-04 - val_mae: 0.0070\n",
            "Epoch 156/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.9879e-05 - mae: 0.0055\n",
            "Epoch 156: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 6.9554e-05 - mae: 0.0054 - val_loss: 2.0228e-04 - val_mae: 0.0070\n",
            "Epoch 157/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.0156e-05 - mae: 0.0055\n",
            "Epoch 157: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.9461e-05 - mae: 0.0054 - val_loss: 2.0183e-04 - val_mae: 0.0070\n",
            "Epoch 158/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.0539e-05 - mae: 0.0055\n",
            "Epoch 158: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 6.9369e-05 - mae: 0.0054 - val_loss: 2.0138e-04 - val_mae: 0.0070\n",
            "Epoch 159/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.0451e-05 - mae: 0.0055\n",
            "Epoch 159: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 6.9276e-05 - mae: 0.0054 - val_loss: 2.0093e-04 - val_mae: 0.0069\n",
            "Epoch 160/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.9888e-05 - mae: 0.0054\n",
            "Epoch 160: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 6.9182e-05 - mae: 0.0054 - val_loss: 2.0048e-04 - val_mae: 0.0069\n",
            "Epoch 161/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.9423e-05 - mae: 0.0054\n",
            "Epoch 161: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 6.9089e-05 - mae: 0.0054 - val_loss: 2.0003e-04 - val_mae: 0.0069\n",
            "Epoch 162/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.9332e-05 - mae: 0.0054\n",
            "Epoch 162: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 6.8996e-05 - mae: 0.0054 - val_loss: 1.9958e-04 - val_mae: 0.0069\n",
            "Epoch 163/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.0101e-05 - mae: 0.0054\n",
            "Epoch 163: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.8902e-05 - mae: 0.0054 - val_loss: 1.9913e-04 - val_mae: 0.0069\n",
            "Epoch 164/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.9530e-05 - mae: 0.0054\n",
            "Epoch 164: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.8809e-05 - mae: 0.0054 - val_loss: 1.9869e-04 - val_mae: 0.0069\n",
            "Epoch 165/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.9924e-05 - mae: 0.0054\n",
            "Epoch 165: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.8715e-05 - mae: 0.0054 - val_loss: 1.9824e-04 - val_mae: 0.0069\n",
            "Epoch 166/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.9836e-05 - mae: 0.0054\n",
            "Epoch 166: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.8621e-05 - mae: 0.0054 - val_loss: 1.9780e-04 - val_mae: 0.0069\n",
            "Epoch 167/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.9259e-05 - mae: 0.0054\n",
            "Epoch 167: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.8527e-05 - mae: 0.0054 - val_loss: 1.9736e-04 - val_mae: 0.0069\n",
            "Epoch 168/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.9168e-05 - mae: 0.0054\n",
            "Epoch 168: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 6.8433e-05 - mae: 0.0054 - val_loss: 1.9691e-04 - val_mae: 0.0069\n",
            "Epoch 169/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.9077e-05 - mae: 0.0054\n",
            "Epoch 169: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 6.8338e-05 - mae: 0.0054 - val_loss: 1.9647e-04 - val_mae: 0.0069\n",
            "Epoch 170/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.8986e-05 - mae: 0.0054\n",
            "Epoch 170: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 6.8244e-05 - mae: 0.0054 - val_loss: 1.9603e-04 - val_mae: 0.0069\n",
            "Epoch 171/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.8500e-05 - mae: 0.0054\n",
            "Epoch 171: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.8150e-05 - mae: 0.0054 - val_loss: 1.9559e-04 - val_mae: 0.0069\n",
            "Epoch 172/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.9301e-05 - mae: 0.0054\n",
            "Epoch 172: val_loss improved from 0.00020 to 0.00020, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 6.8055e-05 - mae: 0.0054 - val_loss: 1.9515e-04 - val_mae: 0.0069\n",
            "Epoch 173/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.8712e-05 - mae: 0.0054\n",
            "Epoch 173: val_loss improved from 0.00020 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.7960e-05 - mae: 0.0054 - val_loss: 1.9471e-04 - val_mae: 0.0068\n",
            "Epoch 174/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.8621e-05 - mae: 0.0054\n",
            "Epoch 174: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 6.7865e-05 - mae: 0.0053 - val_loss: 1.9427e-04 - val_mae: 0.0068\n",
            "Epoch 175/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.9031e-05 - mae: 0.0054\n",
            "Epoch 175: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.7770e-05 - mae: 0.0053 - val_loss: 1.9384e-04 - val_mae: 0.0068\n",
            "Epoch 176/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.8940e-05 - mae: 0.0054\n",
            "Epoch 176: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 6.7675e-05 - mae: 0.0053 - val_loss: 1.9340e-04 - val_mae: 0.0068\n",
            "Epoch 177/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.7940e-05 - mae: 0.0053\n",
            "Epoch 177: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 6.7580e-05 - mae: 0.0053 - val_loss: 1.9296e-04 - val_mae: 0.0068\n",
            "Epoch 178/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.8253e-05 - mae: 0.0053\n",
            "Epoch 178: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 6.7484e-05 - mae: 0.0053 - val_loss: 1.9253e-04 - val_mae: 0.0068\n",
            "Epoch 179/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.8668e-05 - mae: 0.0053\n",
            "Epoch 179: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 6.7389e-05 - mae: 0.0053 - val_loss: 1.9209e-04 - val_mae: 0.0068\n",
            "Epoch 180/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 6.7658e-05 - mae: 0.0053\n",
            "Epoch 180: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 6.7293e-05 - mae: 0.0053 - val_loss: 1.9166e-04 - val_mae: 0.0068\n",
            "Epoch 181/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.7563e-05 - mae: 0.0053\n",
            "Epoch 181: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 6.7197e-05 - mae: 0.0053 - val_loss: 1.9123e-04 - val_mae: 0.0068\n",
            "Epoch 182/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.7882e-05 - mae: 0.0053\n",
            "Epoch 182: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 6.7101e-05 - mae: 0.0053 - val_loss: 1.9080e-04 - val_mae: 0.0068\n",
            "Epoch 183/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.7374e-05 - mae: 0.0053\n",
            "Epoch 183: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 6.7005e-05 - mae: 0.0053 - val_loss: 1.9037e-04 - val_mae: 0.0068\n",
            "Epoch 184/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.7280e-05 - mae: 0.0053\n",
            "Epoch 184: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 6.6909e-05 - mae: 0.0053 - val_loss: 1.8993e-04 - val_mae: 0.0068\n",
            "Epoch 185/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.8119e-05 - mae: 0.0053\n",
            "Epoch 185: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.6813e-05 - mae: 0.0053 - val_loss: 1.8951e-04 - val_mae: 0.0068\n",
            "Epoch 186/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.8027e-05 - mae: 0.0053\n",
            "Epoch 186: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.6717e-05 - mae: 0.0053 - val_loss: 1.8908e-04 - val_mae: 0.0068\n",
            "Epoch 187/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.7416e-05 - mae: 0.0053\n",
            "Epoch 187: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 6.6620e-05 - mae: 0.0053 - val_loss: 1.8865e-04 - val_mae: 0.0067\n",
            "Epoch 188/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.6899e-05 - mae: 0.0053\n",
            "Epoch 188: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.6523e-05 - mae: 0.0053 - val_loss: 1.8822e-04 - val_mae: 0.0067\n",
            "Epoch 189/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.7750e-05 - mae: 0.0053\n",
            "Epoch 189: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.6427e-05 - mae: 0.0053 - val_loss: 1.8779e-04 - val_mae: 0.0067\n",
            "Epoch 190/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.7134e-05 - mae: 0.0053\n",
            "Epoch 190: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.6330e-05 - mae: 0.0053 - val_loss: 1.8737e-04 - val_mae: 0.0067\n",
            "Epoch 191/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.6613e-05 - mae: 0.0053\n",
            "Epoch 191: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 6.6233e-05 - mae: 0.0053 - val_loss: 1.8694e-04 - val_mae: 0.0067\n",
            "Epoch 192/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.7471e-05 - mae: 0.0053\n",
            "Epoch 192: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 6.6136e-05 - mae: 0.0052 - val_loss: 1.8652e-04 - val_mae: 0.0067\n",
            "Epoch 193/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.7378e-05 - mae: 0.0053\n",
            "Epoch 193: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.6039e-05 - mae: 0.0052 - val_loss: 1.8609e-04 - val_mae: 0.0067\n",
            "Epoch 194/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.7284e-05 - mae: 0.0053\n",
            "Epoch 194: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 6.5941e-05 - mae: 0.0052 - val_loss: 1.8567e-04 - val_mae: 0.0067\n",
            "Epoch 195/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.6661e-05 - mae: 0.0052\n",
            "Epoch 195: val_loss improved from 0.00019 to 0.00019, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 6.5844e-05 - mae: 0.0052 - val_loss: 1.8525e-04 - val_mae: 0.0067\n",
            "Epoch 196/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.7097e-05 - mae: 0.0053\n",
            "Epoch 196: val_loss improved from 0.00019 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 6.5746e-05 - mae: 0.0052 - val_loss: 1.8483e-04 - val_mae: 0.0067\n",
            "Epoch 197/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.6471e-05 - mae: 0.0052\n",
            "Epoch 197: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 6.5649e-05 - mae: 0.0052 - val_loss: 1.8441e-04 - val_mae: 0.0067\n",
            "Epoch 198/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.6375e-05 - mae: 0.0052\n",
            "Epoch 198: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.5551e-05 - mae: 0.0052 - val_loss: 1.8399e-04 - val_mae: 0.0067\n",
            "Epoch 199/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.6280e-05 - mae: 0.0052\n",
            "Epoch 199: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 6.5453e-05 - mae: 0.0052 - val_loss: 1.8357e-04 - val_mae: 0.0067\n",
            "Epoch 200/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.6184e-05 - mae: 0.0052\n",
            "Epoch 200: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.5354e-05 - mae: 0.0052 - val_loss: 1.8315e-04 - val_mae: 0.0067\n",
            "Epoch 201/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.5648e-05 - mae: 0.0052\n",
            "Epoch 201: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 6.5256e-05 - mae: 0.0052 - val_loss: 1.8273e-04 - val_mae: 0.0066\n",
            "Epoch 202/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.5550e-05 - mae: 0.0052\n",
            "Epoch 202: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 6.5158e-05 - mae: 0.0052 - val_loss: 1.8232e-04 - val_mae: 0.0066\n",
            "Epoch 203/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.6435e-05 - mae: 0.0052\n",
            "Epoch 203: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 6.5059e-05 - mae: 0.0052 - val_loss: 1.8190e-04 - val_mae: 0.0066\n",
            "Epoch 204/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.5355e-05 - mae: 0.0052\n",
            "Epoch 204: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 6.4960e-05 - mae: 0.0052 - val_loss: 1.8148e-04 - val_mae: 0.0066\n",
            "Epoch 205/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.6244e-05 - mae: 0.0052\n",
            "Epoch 205: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 6.4862e-05 - mae: 0.0052 - val_loss: 1.8107e-04 - val_mae: 0.0066\n",
            "Epoch 206/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.5606e-05 - mae: 0.0052\n",
            "Epoch 206: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 6.4763e-05 - mae: 0.0052 - val_loss: 1.8066e-04 - val_mae: 0.0066\n",
            "Epoch 207/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.6052e-05 - mae: 0.0052\n",
            "Epoch 207: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 6.4664e-05 - mae: 0.0052 - val_loss: 1.8024e-04 - val_mae: 0.0066\n",
            "Epoch 208/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.5412e-05 - mae: 0.0052\n",
            "Epoch 208: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 6.4564e-05 - mae: 0.0052 - val_loss: 1.7983e-04 - val_mae: 0.0066\n",
            "Epoch 209/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.4865e-05 - mae: 0.0052\n",
            "Epoch 209: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.4465e-05 - mae: 0.0052 - val_loss: 1.7942e-04 - val_mae: 0.0066\n",
            "Epoch 210/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.5764e-05 - mae: 0.0052\n",
            "Epoch 210: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 6.4366e-05 - mae: 0.0051 - val_loss: 1.7901e-04 - val_mae: 0.0066\n",
            "Epoch 211/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.4668e-05 - mae: 0.0051\n",
            "Epoch 211: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.4266e-05 - mae: 0.0051 - val_loss: 1.7860e-04 - val_mae: 0.0066\n",
            "Epoch 212/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.4569e-05 - mae: 0.0051\n",
            "Epoch 212: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 6.4166e-05 - mae: 0.0051 - val_loss: 1.7819e-04 - val_mae: 0.0066\n",
            "Epoch 213/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.4925e-05 - mae: 0.0051\n",
            "Epoch 213: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 6.4066e-05 - mae: 0.0051 - val_loss: 1.7778e-04 - val_mae: 0.0066\n",
            "Epoch 214/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.5376e-05 - mae: 0.0052\n",
            "Epoch 214: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 6.3966e-05 - mae: 0.0051 - val_loss: 1.7738e-04 - val_mae: 0.0065\n",
            "Epoch 215/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.4272e-05 - mae: 0.0051\n",
            "Epoch 215: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 6.3866e-05 - mae: 0.0051 - val_loss: 1.7697e-04 - val_mae: 0.0065\n",
            "Epoch 216/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.5181e-05 - mae: 0.0051\n",
            "Epoch 216: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 6.3766e-05 - mae: 0.0051 - val_loss: 1.7656e-04 - val_mae: 0.0065\n",
            "Epoch 217/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.5083e-05 - mae: 0.0051\n",
            "Epoch 217: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 6.3665e-05 - mae: 0.0051 - val_loss: 1.7616e-04 - val_mae: 0.0065\n",
            "Epoch 218/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.4985e-05 - mae: 0.0051\n",
            "Epoch 218: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.3564e-05 - mae: 0.0051 - val_loss: 1.7576e-04 - val_mae: 0.0065\n",
            "Epoch 219/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.4333e-05 - mae: 0.0051\n",
            "Epoch 219: val_loss improved from 0.00018 to 0.00018, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.3464e-05 - mae: 0.0051 - val_loss: 1.7535e-04 - val_mae: 0.0065\n",
            "Epoch 220/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.4234e-05 - mae: 0.0051\n",
            "Epoch 220: val_loss improved from 0.00018 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.3363e-05 - mae: 0.0051 - val_loss: 1.7495e-04 - val_mae: 0.0065\n",
            "Epoch 221/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.4135e-05 - mae: 0.0051\n",
            "Epoch 221: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 6.3262e-05 - mae: 0.0051 - val_loss: 1.7455e-04 - val_mae: 0.0065\n",
            "Epoch 222/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 6.4035e-05 - mae: 0.0051\n",
            "Epoch 222: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.3160e-05 - mae: 0.0051 - val_loss: 1.7415e-04 - val_mae: 0.0065\n",
            "Epoch 223/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.3936e-05 - mae: 0.0051\n",
            "Epoch 223: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 6.3059e-05 - mae: 0.0051 - val_loss: 1.7375e-04 - val_mae: 0.0065\n",
            "Epoch 224/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.4393e-05 - mae: 0.0051\n",
            "Epoch 224: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 6.2957e-05 - mae: 0.0051 - val_loss: 1.7335e-04 - val_mae: 0.0065\n",
            "Epoch 225/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.4294e-05 - mae: 0.0051\n",
            "Epoch 225: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 6.2856e-05 - mae: 0.0051 - val_loss: 1.7295e-04 - val_mae: 0.0065\n",
            "Epoch 226/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.4194e-05 - mae: 0.0051\n",
            "Epoch 226: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 6.2754e-05 - mae: 0.0051 - val_loss: 1.7255e-04 - val_mae: 0.0065\n",
            "Epoch 227/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.3067e-05 - mae: 0.0051\n",
            "Epoch 227: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 6.2652e-05 - mae: 0.0051 - val_loss: 1.7216e-04 - val_mae: 0.0064\n",
            "Epoch 228/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.3434e-05 - mae: 0.0051\n",
            "Epoch 228: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.2550e-05 - mae: 0.0051 - val_loss: 1.7176e-04 - val_mae: 0.0064\n",
            "Epoch 229/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.2864e-05 - mae: 0.0051\n",
            "Epoch 229: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 6.2447e-05 - mae: 0.0050 - val_loss: 1.7137e-04 - val_mae: 0.0064\n",
            "Epoch 230/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.2763e-05 - mae: 0.0050\n",
            "Epoch 230: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.2345e-05 - mae: 0.0050 - val_loss: 1.7097e-04 - val_mae: 0.0064\n",
            "Epoch 231/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.2661e-05 - mae: 0.0050\n",
            "Epoch 231: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.2242e-05 - mae: 0.0050 - val_loss: 1.7058e-04 - val_mae: 0.0064\n",
            "Epoch 232/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.3593e-05 - mae: 0.0051\n",
            "Epoch 232: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.2139e-05 - mae: 0.0050 - val_loss: 1.7019e-04 - val_mae: 0.0064\n",
            "Epoch 233/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.2457e-05 - mae: 0.0050\n",
            "Epoch 233: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 6.2037e-05 - mae: 0.0050 - val_loss: 1.6980e-04 - val_mae: 0.0064\n",
            "Epoch 234/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.2354e-05 - mae: 0.0050\n",
            "Epoch 234: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.1934e-05 - mae: 0.0050 - val_loss: 1.6941e-04 - val_mae: 0.0064\n",
            "Epoch 235/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.3290e-05 - mae: 0.0050\n",
            "Epoch 235: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.1831e-05 - mae: 0.0050 - val_loss: 1.6902e-04 - val_mae: 0.0064\n",
            "Epoch 236/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.3188e-05 - mae: 0.0050\n",
            "Epoch 236: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.1727e-05 - mae: 0.0050 - val_loss: 1.6863e-04 - val_mae: 0.0064\n",
            "Epoch 237/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.3086e-05 - mae: 0.0050\n",
            "Epoch 237: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.1624e-05 - mae: 0.0050 - val_loss: 1.6825e-04 - val_mae: 0.0064\n",
            "Epoch 238/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.2419e-05 - mae: 0.0050\n",
            "Epoch 238: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 6.1520e-05 - mae: 0.0050 - val_loss: 1.6786e-04 - val_mae: 0.0064\n",
            "Epoch 239/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.1840e-05 - mae: 0.0050\n",
            "Epoch 239: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.1417e-05 - mae: 0.0050 - val_loss: 1.6747e-04 - val_mae: 0.0064\n",
            "Epoch 240/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.1737e-05 - mae: 0.0050\n",
            "Epoch 240: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 6.1313e-05 - mae: 0.0050 - val_loss: 1.6709e-04 - val_mae: 0.0063\n",
            "Epoch 241/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.2678e-05 - mae: 0.0050\n",
            "Epoch 241: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 6.1209e-05 - mae: 0.0050 - val_loss: 1.6671e-04 - val_mae: 0.0063\n",
            "Epoch 242/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.2009e-05 - mae: 0.0050\n",
            "Epoch 242: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 6.1105e-05 - mae: 0.0050 - val_loss: 1.6633e-04 - val_mae: 0.0063\n",
            "Epoch 243/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.1427e-05 - mae: 0.0050\n",
            "Epoch 243: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 6.1001e-05 - mae: 0.0050 - val_loss: 1.6594e-04 - val_mae: 0.0063\n",
            "Epoch 244/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.1803e-05 - mae: 0.0050\n",
            "Epoch 244: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 6.0897e-05 - mae: 0.0050 - val_loss: 1.6556e-04 - val_mae: 0.0063\n",
            "Epoch 245/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 6.1699e-05 - mae: 0.0050\n",
            "Epoch 245: val_loss improved from 0.00017 to 0.00017, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 6.0792e-05 - mae: 0.0050 - val_loss: 1.6518e-04 - val_mae: 0.0063\n",
            "Epoch 246/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.1115e-05 - mae: 0.0050\n",
            "Epoch 246: val_loss improved from 0.00017 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 6.0688e-05 - mae: 0.0050 - val_loss: 1.6481e-04 - val_mae: 0.0063\n",
            "Epoch 247/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.1011e-05 - mae: 0.0050\n",
            "Epoch 247: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 6.0583e-05 - mae: 0.0049 - val_loss: 1.6443e-04 - val_mae: 0.0063\n",
            "Epoch 248/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.0907e-05 - mae: 0.0049\n",
            "Epoch 248: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.0479e-05 - mae: 0.0049 - val_loss: 1.6405e-04 - val_mae: 0.0063\n",
            "Epoch 249/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.0803e-05 - mae: 0.0049\n",
            "Epoch 249: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 6.0374e-05 - mae: 0.0049 - val_loss: 1.6368e-04 - val_mae: 0.0063\n",
            "Epoch 250/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.1751e-05 - mae: 0.0050\n",
            "Epoch 250: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 6.0269e-05 - mae: 0.0049 - val_loss: 1.6330e-04 - val_mae: 0.0063\n",
            "Epoch 251/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.0594e-05 - mae: 0.0049\n",
            "Epoch 251: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.0165e-05 - mae: 0.0049 - val_loss: 1.6293e-04 - val_mae: 0.0063\n",
            "Epoch 252/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.0490e-05 - mae: 0.0049\n",
            "Epoch 252: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.0060e-05 - mae: 0.0049 - val_loss: 1.6256e-04 - val_mae: 0.0063\n",
            "Epoch 253/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.0385e-05 - mae: 0.0049\n",
            "Epoch 253: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 5.9955e-05 - mae: 0.0049 - val_loss: 1.6219e-04 - val_mae: 0.0063\n",
            "Epoch 254/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.0281e-05 - mae: 0.0049\n",
            "Epoch 254: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 5.9850e-05 - mae: 0.0049 - val_loss: 1.6182e-04 - val_mae: 0.0062\n",
            "Epoch 255/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.0661e-05 - mae: 0.0049\n",
            "Epoch 255: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 5.9745e-05 - mae: 0.0049 - val_loss: 1.6145e-04 - val_mae: 0.0062\n",
            "Epoch 256/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.0072e-05 - mae: 0.0049\n",
            "Epoch 256: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 5.9640e-05 - mae: 0.0049 - val_loss: 1.6108e-04 - val_mae: 0.0062\n",
            "Epoch 257/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.9967e-05 - mae: 0.0049\n",
            "Epoch 257: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 5.9535e-05 - mae: 0.0049 - val_loss: 1.6071e-04 - val_mae: 0.0062\n",
            "Epoch 258/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.0348e-05 - mae: 0.0049\n",
            "Epoch 258: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 5.9430e-05 - mae: 0.0049 - val_loss: 1.6035e-04 - val_mae: 0.0062\n",
            "Epoch 259/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.9757e-05 - mae: 0.0049\n",
            "Epoch 259: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 5.9325e-05 - mae: 0.0049 - val_loss: 1.5998e-04 - val_mae: 0.0062\n",
            "Epoch 260/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.9653e-05 - mae: 0.0049\n",
            "Epoch 260: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 5.9220e-05 - mae: 0.0049 - val_loss: 1.5962e-04 - val_mae: 0.0062\n",
            "Epoch 261/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.0607e-05 - mae: 0.0049\n",
            "Epoch 261: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 5.9115e-05 - mae: 0.0049 - val_loss: 1.5926e-04 - val_mae: 0.0062\n",
            "Epoch 262/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.9931e-05 - mae: 0.0049\n",
            "Epoch 262: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 5.9010e-05 - mae: 0.0049 - val_loss: 1.5889e-04 - val_mae: 0.0062\n",
            "Epoch 263/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.9339e-05 - mae: 0.0049\n",
            "Epoch 263: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 5.8906e-05 - mae: 0.0049 - val_loss: 1.5853e-04 - val_mae: 0.0062\n",
            "Epoch 264/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.9723e-05 - mae: 0.0049\n",
            "Epoch 264: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 5.8801e-05 - mae: 0.0048 - val_loss: 1.5817e-04 - val_mae: 0.0062\n",
            "Epoch 265/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.9131e-05 - mae: 0.0048\n",
            "Epoch 265: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 5.8697e-05 - mae: 0.0048 - val_loss: 1.5781e-04 - val_mae: 0.0062\n",
            "Epoch 266/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.9026e-05 - mae: 0.0048\n",
            "Epoch 266: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 5.8592e-05 - mae: 0.0048 - val_loss: 1.5745e-04 - val_mae: 0.0062\n",
            "Epoch 267/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.8922e-05 - mae: 0.0048\n",
            "Epoch 267: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 5.8487e-05 - mae: 0.0048 - val_loss: 1.5710e-04 - val_mae: 0.0062\n",
            "Epoch 268/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.9307e-05 - mae: 0.0048\n",
            "Epoch 268: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 5.8383e-05 - mae: 0.0048 - val_loss: 1.5674e-04 - val_mae: 0.0061\n",
            "Epoch 269/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.9775e-05 - mae: 0.0048\n",
            "Epoch 269: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 5.8279e-05 - mae: 0.0048 - val_loss: 1.5638e-04 - val_mae: 0.0061\n",
            "Epoch 270/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.9671e-05 - mae: 0.0048\n",
            "Epoch 270: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 5.8175e-05 - mae: 0.0048 - val_loss: 1.5603e-04 - val_mae: 0.0061\n",
            "Epoch 271/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.8506e-05 - mae: 0.0048\n",
            "Epoch 271: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 5.8071e-05 - mae: 0.0048 - val_loss: 1.5567e-04 - val_mae: 0.0061\n",
            "Epoch 272/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.8403e-05 - mae: 0.0048\n",
            "Epoch 272: val_loss improved from 0.00016 to 0.00016, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 5.7967e-05 - mae: 0.0048 - val_loss: 1.5532e-04 - val_mae: 0.0061\n",
            "Epoch 273/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.8299e-05 - mae: 0.0048\n",
            "Epoch 273: val_loss improved from 0.00016 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 5.7864e-05 - mae: 0.0048 - val_loss: 1.5497e-04 - val_mae: 0.0061\n",
            "Epoch 274/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.8196e-05 - mae: 0.0048\n",
            "Epoch 274: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 5.7760e-05 - mae: 0.0048 - val_loss: 1.5462e-04 - val_mae: 0.0061\n",
            "Epoch 275/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.9155e-05 - mae: 0.0048\n",
            "Epoch 275: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 5.7657e-05 - mae: 0.0048 - val_loss: 1.5427e-04 - val_mae: 0.0061\n",
            "Epoch 276/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.7990e-05 - mae: 0.0048\n",
            "Epoch 276: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 5.7554e-05 - mae: 0.0048 - val_loss: 1.5391e-04 - val_mae: 0.0061\n",
            "Epoch 277/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.8379e-05 - mae: 0.0048\n",
            "Epoch 277: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 5.7452e-05 - mae: 0.0048 - val_loss: 1.5356e-04 - val_mae: 0.0061\n",
            "Epoch 278/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.7786e-05 - mae: 0.0048\n",
            "Epoch 278: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 5.7349e-05 - mae: 0.0048 - val_loss: 1.5321e-04 - val_mae: 0.0061\n",
            "Epoch 279/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.7683e-05 - mae: 0.0048\n",
            "Epoch 279: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 5.7247e-05 - mae: 0.0048 - val_loss: 1.5286e-04 - val_mae: 0.0061\n",
            "Epoch 280/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.7581e-05 - mae: 0.0048\n",
            "Epoch 280: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 5.7145e-05 - mae: 0.0048 - val_loss: 1.5252e-04 - val_mae: 0.0061\n",
            "Epoch 281/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.7971e-05 - mae: 0.0048\n",
            "Epoch 281: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 5.7043e-05 - mae: 0.0048 - val_loss: 1.5217e-04 - val_mae: 0.0061\n",
            "Epoch 282/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.7869e-05 - mae: 0.0048\n",
            "Epoch 282: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 5.6942e-05 - mae: 0.0047 - val_loss: 1.5182e-04 - val_mae: 0.0061\n",
            "Epoch 283/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 5.7768e-05 - mae: 0.0048\n",
            "Epoch 283: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 5.6840e-05 - mae: 0.0047 - val_loss: 1.5147e-04 - val_mae: 0.0061\n",
            "Epoch 284/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.7176e-05 - mae: 0.0047\n",
            "Epoch 284: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 5.6739e-05 - mae: 0.0047 - val_loss: 1.5112e-04 - val_mae: 0.0060\n",
            "Epoch 285/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.8136e-05 - mae: 0.0048\n",
            "Epoch 285: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 5.6639e-05 - mae: 0.0047 - val_loss: 1.5078e-04 - val_mae: 0.0060\n",
            "Epoch 286/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.8035e-05 - mae: 0.0048\n",
            "Epoch 286: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 5.6538e-05 - mae: 0.0047 - val_loss: 1.5043e-04 - val_mae: 0.0060\n",
            "Epoch 287/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.7934e-05 - mae: 0.0048\n",
            "Epoch 287: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 5.6437e-05 - mae: 0.0047 - val_loss: 1.5008e-04 - val_mae: 0.0060\n",
            "Epoch 288/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.7265e-05 - mae: 0.0047\n",
            "Epoch 288: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 5.6337e-05 - mae: 0.0047 - val_loss: 1.4973e-04 - val_mae: 0.0060\n",
            "Epoch 289/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.6674e-05 - mae: 0.0047\n",
            "Epoch 289: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 5.6238e-05 - mae: 0.0047 - val_loss: 1.4938e-04 - val_mae: 0.0060\n",
            "Epoch 290/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.7065e-05 - mae: 0.0047\n",
            "Epoch 290: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 5.6138e-05 - mae: 0.0047 - val_loss: 1.4904e-04 - val_mae: 0.0060\n",
            "Epoch 291/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.6475e-05 - mae: 0.0047\n",
            "Epoch 291: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 5.6039e-05 - mae: 0.0047 - val_loss: 1.4869e-04 - val_mae: 0.0060\n",
            "Epoch 292/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.6376e-05 - mae: 0.0047\n",
            "Epoch 292: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 5.5940e-05 - mae: 0.0047 - val_loss: 1.4834e-04 - val_mae: 0.0060\n",
            "Epoch 293/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.7334e-05 - mae: 0.0047\n",
            "Epoch 293: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 5.5841e-05 - mae: 0.0047 - val_loss: 1.4799e-04 - val_mae: 0.0060\n",
            "Epoch 294/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.6668e-05 - mae: 0.0047\n",
            "Epoch 294: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 5.5742e-05 - mae: 0.0047 - val_loss: 1.4765e-04 - val_mae: 0.0060\n",
            "Epoch 295/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.6570e-05 - mae: 0.0047\n",
            "Epoch 295: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 5.5644e-05 - mae: 0.0047 - val_loss: 1.4730e-04 - val_mae: 0.0060\n",
            "Epoch 296/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.7036e-05 - mae: 0.0047\n",
            "Epoch 296: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 5.5545e-05 - mae: 0.0047 - val_loss: 1.4695e-04 - val_mae: 0.0060\n",
            "Epoch 297/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.6937e-05 - mae: 0.0047\n",
            "Epoch 297: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 5.5447e-05 - mae: 0.0047 - val_loss: 1.4660e-04 - val_mae: 0.0060\n",
            "Epoch 298/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.5785e-05 - mae: 0.0047\n",
            "Epoch 298: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 5.5350e-05 - mae: 0.0047 - val_loss: 1.4625e-04 - val_mae: 0.0059\n",
            "Epoch 299/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.6740e-05 - mae: 0.0047\n",
            "Epoch 299: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 5.5252e-05 - mae: 0.0047 - val_loss: 1.4591e-04 - val_mae: 0.0059\n",
            "Epoch 300/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.5589e-05 - mae: 0.0047\n",
            "Epoch 300: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 5.5154e-05 - mae: 0.0047 - val_loss: 1.4556e-04 - val_mae: 0.0059\n",
            "Epoch 301/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.5491e-05 - mae: 0.0047\n",
            "Epoch 301: val_loss improved from 0.00015 to 0.00015, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 5.5057e-05 - mae: 0.0047 - val_loss: 1.4521e-04 - val_mae: 0.0059\n",
            "Epoch 302/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.5882e-05 - mae: 0.0047\n",
            "Epoch 302: val_loss improved from 0.00015 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 5.4960e-05 - mae: 0.0047 - val_loss: 1.4486e-04 - val_mae: 0.0059\n",
            "Epoch 303/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.5296e-05 - mae: 0.0047\n",
            "Epoch 303: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 5.4863e-05 - mae: 0.0047 - val_loss: 1.4451e-04 - val_mae: 0.0059\n",
            "Epoch 304/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.6247e-05 - mae: 0.0047\n",
            "Epoch 304: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 5.4766e-05 - mae: 0.0047 - val_loss: 1.4417e-04 - val_mae: 0.0059\n",
            "Epoch 305/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.6149e-05 - mae: 0.0047\n",
            "Epoch 305: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 5.4669e-05 - mae: 0.0047 - val_loss: 1.4382e-04 - val_mae: 0.0059\n",
            "Epoch 306/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.5492e-05 - mae: 0.0047\n",
            "Epoch 306: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 5.4572e-05 - mae: 0.0047 - val_loss: 1.4347e-04 - val_mae: 0.0059\n",
            "Epoch 307/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.5953e-05 - mae: 0.0047\n",
            "Epoch 307: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 5.4476e-05 - mae: 0.0046 - val_loss: 1.4312e-04 - val_mae: 0.0059\n",
            "Epoch 308/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.5856e-05 - mae: 0.0047\n",
            "Epoch 308: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 5.4380e-05 - mae: 0.0046 - val_loss: 1.4278e-04 - val_mae: 0.0059\n",
            "Epoch 309/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.4715e-05 - mae: 0.0046\n",
            "Epoch 309: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 5.4284e-05 - mae: 0.0046 - val_loss: 1.4243e-04 - val_mae: 0.0059\n",
            "Epoch 310/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.4619e-05 - mae: 0.0046\n",
            "Epoch 310: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 5.4188e-05 - mae: 0.0046 - val_loss: 1.4209e-04 - val_mae: 0.0059\n",
            "Epoch 311/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.5563e-05 - mae: 0.0047\n",
            "Epoch 311: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 5.4092e-05 - mae: 0.0046 - val_loss: 1.4174e-04 - val_mae: 0.0059\n",
            "Epoch 312/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.4427e-05 - mae: 0.0046\n",
            "Epoch 312: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 5.3996e-05 - mae: 0.0046 - val_loss: 1.4140e-04 - val_mae: 0.0059\n",
            "Epoch 313/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.5369e-05 - mae: 0.0047\n",
            "Epoch 313: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 5.3901e-05 - mae: 0.0046 - val_loss: 1.4105e-04 - val_mae: 0.0058\n",
            "Epoch 314/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.5271e-05 - mae: 0.0046\n",
            "Epoch 314: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 5.3805e-05 - mae: 0.0046 - val_loss: 1.4071e-04 - val_mae: 0.0058\n",
            "Epoch 315/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.4139e-05 - mae: 0.0046\n",
            "Epoch 315: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 5.3710e-05 - mae: 0.0046 - val_loss: 1.4037e-04 - val_mae: 0.0058\n",
            "Epoch 316/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.5077e-05 - mae: 0.0046\n",
            "Epoch 316: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 5.3615e-05 - mae: 0.0046 - val_loss: 1.4003e-04 - val_mae: 0.0058\n",
            "Epoch 317/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.4981e-05 - mae: 0.0046\n",
            "Epoch 317: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 5.3520e-05 - mae: 0.0046 - val_loss: 1.3969e-04 - val_mae: 0.0058\n",
            "Epoch 318/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.4884e-05 - mae: 0.0046\n",
            "Epoch 318: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 5.3426e-05 - mae: 0.0046 - val_loss: 1.3935e-04 - val_mae: 0.0058\n",
            "Epoch 319/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.4238e-05 - mae: 0.0046\n",
            "Epoch 319: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 5.3331e-05 - mae: 0.0046 - val_loss: 1.3901e-04 - val_mae: 0.0058\n",
            "Epoch 320/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 5.4142e-05 - mae: 0.0046\n",
            "Epoch 320: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 5.3237e-05 - mae: 0.0046 - val_loss: 1.3867e-04 - val_mae: 0.0058\n",
            "Epoch 321/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 5.3568e-05 - mae: 0.0046\n",
            "Epoch 321: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 5.3143e-05 - mae: 0.0046 - val_loss: 1.3834e-04 - val_mae: 0.0058\n",
            "Epoch 322/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.3474e-05 - mae: 0.0046\n",
            "Epoch 322: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 5.3049e-05 - mae: 0.0046 - val_loss: 1.3801e-04 - val_mae: 0.0058\n",
            "Epoch 323/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 5.3857e-05 - mae: 0.0046\n",
            "Epoch 323: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 5.2955e-05 - mae: 0.0046 - val_loss: 1.3767e-04 - val_mae: 0.0058\n",
            "Epoch 324/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.4307e-05 - mae: 0.0046\n",
            "Epoch 324: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 5.2862e-05 - mae: 0.0046 - val_loss: 1.3734e-04 - val_mae: 0.0058\n",
            "Epoch 325/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.3667e-05 - mae: 0.0046\n",
            "Epoch 325: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 5.2768e-05 - mae: 0.0046 - val_loss: 1.3702e-04 - val_mae: 0.0058\n",
            "Epoch 326/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.3098e-05 - mae: 0.0046\n",
            "Epoch 326: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 5.2675e-05 - mae: 0.0046 - val_loss: 1.3669e-04 - val_mae: 0.0058\n",
            "Epoch 327/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.3479e-05 - mae: 0.0046\n",
            "Epoch 327: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 5.2583e-05 - mae: 0.0046 - val_loss: 1.3637e-04 - val_mae: 0.0057\n",
            "Epoch 328/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.3926e-05 - mae: 0.0046\n",
            "Epoch 328: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 5.2490e-05 - mae: 0.0046 - val_loss: 1.3604e-04 - val_mae: 0.0057\n",
            "Epoch 329/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.3291e-05 - mae: 0.0046\n",
            "Epoch 329: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 5.2398e-05 - mae: 0.0046 - val_loss: 1.3572e-04 - val_mae: 0.0057\n",
            "Epoch 330/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.3197e-05 - mae: 0.0046\n",
            "Epoch 330: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 5.2305e-05 - mae: 0.0046 - val_loss: 1.3540e-04 - val_mae: 0.0057\n",
            "Epoch 331/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.3104e-05 - mae: 0.0046\n",
            "Epoch 331: val_loss improved from 0.00014 to 0.00014, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 5.2214e-05 - mae: 0.0046 - val_loss: 1.3509e-04 - val_mae: 0.0057\n",
            "Epoch 332/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.3549e-05 - mae: 0.0046\n",
            "Epoch 332: val_loss improved from 0.00014 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 5.2122e-05 - mae: 0.0045 - val_loss: 1.3477e-04 - val_mae: 0.0057\n",
            "Epoch 333/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.3455e-05 - mae: 0.0046\n",
            "Epoch 333: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 5.2031e-05 - mae: 0.0045 - val_loss: 1.3446e-04 - val_mae: 0.0057\n",
            "Epoch 334/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.2357e-05 - mae: 0.0045\n",
            "Epoch 334: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 5.1940e-05 - mae: 0.0045 - val_loss: 1.3415e-04 - val_mae: 0.0057\n",
            "Epoch 335/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.3268e-05 - mae: 0.0046\n",
            "Epoch 335: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 5.1849e-05 - mae: 0.0045 - val_loss: 1.3384e-04 - val_mae: 0.0057\n",
            "Epoch 336/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.2641e-05 - mae: 0.0045\n",
            "Epoch 336: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 5.1759e-05 - mae: 0.0045 - val_loss: 1.3354e-04 - val_mae: 0.0057\n",
            "Epoch 337/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.2083e-05 - mae: 0.0045\n",
            "Epoch 337: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 5.1668e-05 - mae: 0.0045 - val_loss: 1.3324e-04 - val_mae: 0.0057\n",
            "Epoch 338/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.1992e-05 - mae: 0.0045\n",
            "Epoch 338: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 5.1578e-05 - mae: 0.0045 - val_loss: 1.3293e-04 - val_mae: 0.0057\n",
            "Epoch 339/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 5.1902e-05 - mae: 0.0045\n",
            "Epoch 339: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 5.1489e-05 - mae: 0.0045 - val_loss: 1.3264e-04 - val_mae: 0.0057\n",
            "Epoch 340/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.2805e-05 - mae: 0.0045\n",
            "Epoch 340: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 5.1400e-05 - mae: 0.0045 - val_loss: 1.3234e-04 - val_mae: 0.0057\n",
            "Epoch 341/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.2713e-05 - mae: 0.0045\n",
            "Epoch 341: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 5.1311e-05 - mae: 0.0045 - val_loss: 1.3205e-04 - val_mae: 0.0057\n",
            "Epoch 342/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.2622e-05 - mae: 0.0045\n",
            "Epoch 342: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 5.1222e-05 - mae: 0.0045 - val_loss: 1.3176e-04 - val_mae: 0.0056\n",
            "Epoch 343/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.2531e-05 - mae: 0.0045\n",
            "Epoch 343: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 5.1134e-05 - mae: 0.0045 - val_loss: 1.3147e-04 - val_mae: 0.0056\n",
            "Epoch 344/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.1915e-05 - mae: 0.0045\n",
            "Epoch 344: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 5.1046e-05 - mae: 0.0045 - val_loss: 1.3118e-04 - val_mae: 0.0056\n",
            "Epoch 345/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.1366e-05 - mae: 0.0045\n",
            "Epoch 345: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 5.0958e-05 - mae: 0.0045 - val_loss: 1.3090e-04 - val_mae: 0.0056\n",
            "Epoch 346/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.2259e-05 - mae: 0.0045\n",
            "Epoch 346: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 5.0871e-05 - mae: 0.0045 - val_loss: 1.3062e-04 - val_mae: 0.0056\n",
            "Epoch 347/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.1190e-05 - mae: 0.0045\n",
            "Epoch 347: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 5.0783e-05 - mae: 0.0045 - val_loss: 1.3034e-04 - val_mae: 0.0056\n",
            "Epoch 348/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.1559e-05 - mae: 0.0045\n",
            "Epoch 348: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 5.0696e-05 - mae: 0.0045 - val_loss: 1.3007e-04 - val_mae: 0.0056\n",
            "Epoch 349/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.1015e-05 - mae: 0.0045\n",
            "Epoch 349: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 5.0610e-05 - mae: 0.0045 - val_loss: 1.2980e-04 - val_mae: 0.0056\n",
            "Epoch 350/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.1383e-05 - mae: 0.0045\n",
            "Epoch 350: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 5.0524e-05 - mae: 0.0045 - val_loss: 1.2953e-04 - val_mae: 0.0056\n",
            "Epoch 351/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.1812e-05 - mae: 0.0045\n",
            "Epoch 351: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 5.0438e-05 - mae: 0.0045 - val_loss: 1.2926e-04 - val_mae: 0.0056\n",
            "Epoch 352/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.1209e-05 - mae: 0.0045\n",
            "Epoch 352: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 5.0353e-05 - mae: 0.0045 - val_loss: 1.2899e-04 - val_mae: 0.0056\n",
            "Epoch 353/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.1636e-05 - mae: 0.0045\n",
            "Epoch 353: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 5.0268e-05 - mae: 0.0045 - val_loss: 1.2873e-04 - val_mae: 0.0056\n",
            "Epoch 354/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.1548e-05 - mae: 0.0045\n",
            "Epoch 354: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 5.0183e-05 - mae: 0.0045 - val_loss: 1.2847e-04 - val_mae: 0.0056\n",
            "Epoch 355/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.1461e-05 - mae: 0.0045\n",
            "Epoch 355: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 5.0098e-05 - mae: 0.0045 - val_loss: 1.2821e-04 - val_mae: 0.0056\n",
            "Epoch 356/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.0413e-05 - mae: 0.0045\n",
            "Epoch 356: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 5.0014e-05 - mae: 0.0045 - val_loss: 1.2796e-04 - val_mae: 0.0056\n",
            "Epoch 357/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.0328e-05 - mae: 0.0045\n",
            "Epoch 357: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 4.9930e-05 - mae: 0.0045 - val_loss: 1.2770e-04 - val_mae: 0.0056\n",
            "Epoch 358/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.0243e-05 - mae: 0.0045\n",
            "Epoch 358: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 4.9846e-05 - mae: 0.0044 - val_loss: 1.2745e-04 - val_mae: 0.0056\n",
            "Epoch 359/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.1113e-05 - mae: 0.0045\n",
            "Epoch 359: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.9762e-05 - mae: 0.0044 - val_loss: 1.2720e-04 - val_mae: 0.0056\n",
            "Epoch 360/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.1026e-05 - mae: 0.0045\n",
            "Epoch 360: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.9679e-05 - mae: 0.0044 - val_loss: 1.2696e-04 - val_mae: 0.0055\n",
            "Epoch 361/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.0940e-05 - mae: 0.0045\n",
            "Epoch 361: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.9596e-05 - mae: 0.0044 - val_loss: 1.2671e-04 - val_mae: 0.0055\n",
            "Epoch 362/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.0351e-05 - mae: 0.0044\n",
            "Epoch 362: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.9513e-05 - mae: 0.0044 - val_loss: 1.2647e-04 - val_mae: 0.0055\n",
            "Epoch 363/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.0768e-05 - mae: 0.0045\n",
            "Epoch 363: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.9430e-05 - mae: 0.0044 - val_loss: 1.2623e-04 - val_mae: 0.0055\n",
            "Epoch 364/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.0683e-05 - mae: 0.0045\n",
            "Epoch 364: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.9348e-05 - mae: 0.0044 - val_loss: 1.2600e-04 - val_mae: 0.0055\n",
            "Epoch 365/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.0598e-05 - mae: 0.0044\n",
            "Epoch 365: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.9266e-05 - mae: 0.0044 - val_loss: 1.2576e-04 - val_mae: 0.0055\n",
            "Epoch 366/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.0512e-05 - mae: 0.0044\n",
            "Epoch 366: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 4.9184e-05 - mae: 0.0044 - val_loss: 1.2553e-04 - val_mae: 0.0055\n",
            "Epoch 367/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.9492e-05 - mae: 0.0044\n",
            "Epoch 367: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.9102e-05 - mae: 0.0044 - val_loss: 1.2530e-04 - val_mae: 0.0055\n",
            "Epoch 368/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.9409e-05 - mae: 0.0044\n",
            "Epoch 368: val_loss improved from 0.00013 to 0.00013, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.9020e-05 - mae: 0.0044 - val_loss: 1.2508e-04 - val_mae: 0.0055\n",
            "Epoch 369/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.9327e-05 - mae: 0.0044\n",
            "Epoch 369: val_loss improved from 0.00013 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.8939e-05 - mae: 0.0044 - val_loss: 1.2485e-04 - val_mae: 0.0055\n",
            "Epoch 370/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.0174e-05 - mae: 0.0044\n",
            "Epoch 370: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.8858e-05 - mae: 0.0044 - val_loss: 1.2463e-04 - val_mae: 0.0055\n",
            "Epoch 371/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.0090e-05 - mae: 0.0044\n",
            "Epoch 371: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.8776e-05 - mae: 0.0044 - val_loss: 1.2441e-04 - val_mae: 0.0055\n",
            "Epoch 372/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.0006e-05 - mae: 0.0044\n",
            "Epoch 372: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.8695e-05 - mae: 0.0044 - val_loss: 1.2419e-04 - val_mae: 0.0055\n",
            "Epoch 373/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.8999e-05 - mae: 0.0044\n",
            "Epoch 373: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.8615e-05 - mae: 0.0044 - val_loss: 1.2398e-04 - val_mae: 0.0055\n",
            "Epoch 374/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.8918e-05 - mae: 0.0044\n",
            "Epoch 374: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 4.8534e-05 - mae: 0.0044 - val_loss: 1.2377e-04 - val_mae: 0.0055\n",
            "Epoch 375/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.8837e-05 - mae: 0.0044\n",
            "Epoch 375: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 4.8453e-05 - mae: 0.0044 - val_loss: 1.2356e-04 - val_mae: 0.0055\n",
            "Epoch 376/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.8755e-05 - mae: 0.0044\n",
            "Epoch 376: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 4.8373e-05 - mae: 0.0044 - val_loss: 1.2335e-04 - val_mae: 0.0055\n",
            "Epoch 377/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.9104e-05 - mae: 0.0044\n",
            "Epoch 377: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 4.8293e-05 - mae: 0.0044 - val_loss: 1.2314e-04 - val_mae: 0.0055\n",
            "Epoch 378/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 4.9022e-05 - mae: 0.0044\n",
            "Epoch 378: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 4.8213e-05 - mae: 0.0044 - val_loss: 1.2294e-04 - val_mae: 0.0055\n",
            "Epoch 379/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.8941e-05 - mae: 0.0044\n",
            "Epoch 379: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.8133e-05 - mae: 0.0044 - val_loss: 1.2274e-04 - val_mae: 0.0055\n",
            "Epoch 380/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.8860e-05 - mae: 0.0044\n",
            "Epoch 380: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.8054e-05 - mae: 0.0044 - val_loss: 1.2255e-04 - val_mae: 0.0055\n",
            "Epoch 381/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.9259e-05 - mae: 0.0044\n",
            "Epoch 381: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.7975e-05 - mae: 0.0044 - val_loss: 1.2235e-04 - val_mae: 0.0055\n",
            "Epoch 382/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.8273e-05 - mae: 0.0044\n",
            "Epoch 382: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.7896e-05 - mae: 0.0043 - val_loss: 1.2216e-04 - val_mae: 0.0055\n",
            "Epoch 383/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.9096e-05 - mae: 0.0044\n",
            "Epoch 383: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 4.7817e-05 - mae: 0.0043 - val_loss: 1.2197e-04 - val_mae: 0.0055\n",
            "Epoch 384/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.9015e-05 - mae: 0.0044\n",
            "Epoch 384: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 4.7739e-05 - mae: 0.0043 - val_loss: 1.2179e-04 - val_mae: 0.0055\n",
            "Epoch 385/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.8934e-05 - mae: 0.0044\n",
            "Epoch 385: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.7660e-05 - mae: 0.0043 - val_loss: 1.2160e-04 - val_mae: 0.0054\n",
            "Epoch 386/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.8853e-05 - mae: 0.0044\n",
            "Epoch 386: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.7582e-05 - mae: 0.0043 - val_loss: 1.2142e-04 - val_mae: 0.0054\n",
            "Epoch 387/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.8772e-05 - mae: 0.0043\n",
            "Epoch 387: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.7504e-05 - mae: 0.0043 - val_loss: 1.2124e-04 - val_mae: 0.0054\n",
            "Epoch 388/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.8692e-05 - mae: 0.0043\n",
            "Epoch 388: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 4.7427e-05 - mae: 0.0043 - val_loss: 1.2107e-04 - val_mae: 0.0054\n",
            "Epoch 389/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.8140e-05 - mae: 0.0043\n",
            "Epoch 389: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.7349e-05 - mae: 0.0043 - val_loss: 1.2089e-04 - val_mae: 0.0054\n",
            "Epoch 390/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.8061e-05 - mae: 0.0043\n",
            "Epoch 390: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.7272e-05 - mae: 0.0043 - val_loss: 1.2072e-04 - val_mae: 0.0054\n",
            "Epoch 391/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.8452e-05 - mae: 0.0043\n",
            "Epoch 391: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.7195e-05 - mae: 0.0043 - val_loss: 1.2055e-04 - val_mae: 0.0054\n",
            "Epoch 392/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.7488e-05 - mae: 0.0043\n",
            "Epoch 392: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 4.7119e-05 - mae: 0.0043 - val_loss: 1.2039e-04 - val_mae: 0.0054\n",
            "Epoch 393/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 4.7826e-05 - mae: 0.0043\n",
            "Epoch 393: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 4.7042e-05 - mae: 0.0043 - val_loss: 1.2023e-04 - val_mae: 0.0054\n",
            "Epoch 394/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 4.7748e-05 - mae: 0.0043\n",
            "Epoch 394: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 4.6966e-05 - mae: 0.0043 - val_loss: 1.2006e-04 - val_mae: 0.0054\n",
            "Epoch 395/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.7671e-05 - mae: 0.0043\n",
            "Epoch 395: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.6890e-05 - mae: 0.0043 - val_loss: 1.1991e-04 - val_mae: 0.0054\n",
            "Epoch 396/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.8058e-05 - mae: 0.0043\n",
            "Epoch 396: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.6815e-05 - mae: 0.0043 - val_loss: 1.1975e-04 - val_mae: 0.0054\n",
            "Epoch 397/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.7105e-05 - mae: 0.0043\n",
            "Epoch 397: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.6740e-05 - mae: 0.0043 - val_loss: 1.1960e-04 - val_mae: 0.0054\n",
            "Epoch 398/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.7440e-05 - mae: 0.0043\n",
            "Epoch 398: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.6665e-05 - mae: 0.0043 - val_loss: 1.1945e-04 - val_mae: 0.0054\n",
            "Epoch 399/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.7825e-05 - mae: 0.0043\n",
            "Epoch 399: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.6590e-05 - mae: 0.0043 - val_loss: 1.1930e-04 - val_mae: 0.0054\n",
            "Epoch 400/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.7747e-05 - mae: 0.0043\n",
            "Epoch 400: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.6515e-05 - mae: 0.0043 - val_loss: 1.1916e-04 - val_mae: 0.0054\n",
            "Epoch 401/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.7212e-05 - mae: 0.0043\n",
            "Epoch 401: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.6441e-05 - mae: 0.0043 - val_loss: 1.1902e-04 - val_mae: 0.0054\n",
            "Epoch 402/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.7136e-05 - mae: 0.0043\n",
            "Epoch 402: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.6366e-05 - mae: 0.0043 - val_loss: 1.1888e-04 - val_mae: 0.0054\n",
            "Epoch 403/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.6654e-05 - mae: 0.0043\n",
            "Epoch 403: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.6292e-05 - mae: 0.0043 - val_loss: 1.1874e-04 - val_mae: 0.0054\n",
            "Epoch 404/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.7440e-05 - mae: 0.0043\n",
            "Epoch 404: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.6218e-05 - mae: 0.0043 - val_loss: 1.1860e-04 - val_mae: 0.0054\n",
            "Epoch 405/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.6909e-05 - mae: 0.0043\n",
            "Epoch 405: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.6144e-05 - mae: 0.0043 - val_loss: 1.1847e-04 - val_mae: 0.0054\n",
            "Epoch 406/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.6430e-05 - mae: 0.0043\n",
            "Epoch 406: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.6071e-05 - mae: 0.0043 - val_loss: 1.1834e-04 - val_mae: 0.0054\n",
            "Epoch 407/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.7211e-05 - mae: 0.0043\n",
            "Epoch 407: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.5997e-05 - mae: 0.0043 - val_loss: 1.1822e-04 - val_mae: 0.0054\n",
            "Epoch 408/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.6683e-05 - mae: 0.0043\n",
            "Epoch 408: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.5924e-05 - mae: 0.0043 - val_loss: 1.1809e-04 - val_mae: 0.0054\n",
            "Epoch 409/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.7059e-05 - mae: 0.0043\n",
            "Epoch 409: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.5850e-05 - mae: 0.0042 - val_loss: 1.1797e-04 - val_mae: 0.0054\n",
            "Epoch 410/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.6133e-05 - mae: 0.0042\n",
            "Epoch 410: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 4.5777e-05 - mae: 0.0042 - val_loss: 1.1785e-04 - val_mae: 0.0054\n",
            "Epoch 411/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.6059e-05 - mae: 0.0042\n",
            "Epoch 411: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 4.5704e-05 - mae: 0.0042 - val_loss: 1.1774e-04 - val_mae: 0.0054\n",
            "Epoch 412/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 4.5986e-05 - mae: 0.0042\n",
            "Epoch 412: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 4.5631e-05 - mae: 0.0042 - val_loss: 1.1762e-04 - val_mae: 0.0054\n",
            "Epoch 413/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 4.6310e-05 - mae: 0.0042\n",
            "Epoch 413: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 4.5558e-05 - mae: 0.0042 - val_loss: 1.1751e-04 - val_mae: 0.0054\n",
            "Epoch 414/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 4.5838e-05 - mae: 0.0042\n",
            "Epoch 414: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 4.5486e-05 - mae: 0.0042 - val_loss: 1.1740e-04 - val_mae: 0.0054\n",
            "Epoch 415/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.6605e-05 - mae: 0.0042\n",
            "Epoch 415: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.5413e-05 - mae: 0.0042 - val_loss: 1.1730e-04 - val_mae: 0.0054\n",
            "Epoch 416/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.6530e-05 - mae: 0.0042\n",
            "Epoch 416: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.5340e-05 - mae: 0.0042 - val_loss: 1.1720e-04 - val_mae: 0.0054\n",
            "Epoch 417/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.6454e-05 - mae: 0.0042\n",
            "Epoch 417: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.5267e-05 - mae: 0.0042 - val_loss: 1.1709e-04 - val_mae: 0.0054\n",
            "Epoch 418/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.5937e-05 - mae: 0.0042\n",
            "Epoch 418: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.5194e-05 - mae: 0.0042 - val_loss: 1.1700e-04 - val_mae: 0.0054\n",
            "Epoch 419/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.5470e-05 - mae: 0.0042\n",
            "Epoch 419: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.5121e-05 - mae: 0.0042 - val_loss: 1.1690e-04 - val_mae: 0.0054\n",
            "Epoch 420/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.6227e-05 - mae: 0.0042\n",
            "Epoch 420: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.5048e-05 - mae: 0.0042 - val_loss: 1.1680e-04 - val_mae: 0.0054\n",
            "Epoch 421/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.6150e-05 - mae: 0.0042\n",
            "Epoch 421: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.4975e-05 - mae: 0.0042 - val_loss: 1.1671e-04 - val_mae: 0.0054\n",
            "Epoch 422/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.6074e-05 - mae: 0.0042\n",
            "Epoch 422: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.4901e-05 - mae: 0.0042 - val_loss: 1.1662e-04 - val_mae: 0.0054\n",
            "Epoch 423/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.5173e-05 - mae: 0.0042\n",
            "Epoch 423: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.4827e-05 - mae: 0.0042 - val_loss: 1.1654e-04 - val_mae: 0.0054\n",
            "Epoch 424/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.5098e-05 - mae: 0.0042\n",
            "Epoch 424: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.4753e-05 - mae: 0.0042 - val_loss: 1.1645e-04 - val_mae: 0.0054\n",
            "Epoch 425/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.5843e-05 - mae: 0.0042\n",
            "Epoch 425: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.4679e-05 - mae: 0.0042 - val_loss: 1.1637e-04 - val_mae: 0.0053\n",
            "Epoch 426/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.4948e-05 - mae: 0.0042\n",
            "Epoch 426: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.4605e-05 - mae: 0.0042 - val_loss: 1.1629e-04 - val_mae: 0.0053\n",
            "Epoch 427/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.5688e-05 - mae: 0.0042\n",
            "Epoch 427: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.4530e-05 - mae: 0.0042 - val_loss: 1.1621e-04 - val_mae: 0.0053\n",
            "Epoch 428/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.4797e-05 - mae: 0.0042\n",
            "Epoch 428: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 4.4456e-05 - mae: 0.0042 - val_loss: 1.1614e-04 - val_mae: 0.0053\n",
            "Epoch 429/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.5534e-05 - mae: 0.0042\n",
            "Epoch 429: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.4382e-05 - mae: 0.0042 - val_loss: 1.1607e-04 - val_mae: 0.0053\n",
            "Epoch 430/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.5029e-05 - mae: 0.0042\n",
            "Epoch 430: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 4.4307e-05 - mae: 0.0042 - val_loss: 1.1600e-04 - val_mae: 0.0053\n",
            "Epoch 431/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.4952e-05 - mae: 0.0042\n",
            "Epoch 431: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 4.4233e-05 - mae: 0.0042 - val_loss: 1.1594e-04 - val_mae: 0.0053\n",
            "Epoch 432/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 4.4877e-05 - mae: 0.0042\n",
            "Epoch 432: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 4.4159e-05 - mae: 0.0042 - val_loss: 1.1588e-04 - val_mae: 0.0053\n",
            "Epoch 433/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 4.4801e-05 - mae: 0.0042\n",
            "Epoch 433: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 4.4085e-05 - mae: 0.0042 - val_loss: 1.1582e-04 - val_mae: 0.0053\n",
            "Epoch 434/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.4347e-05 - mae: 0.0042\n",
            "Epoch 434: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.4012e-05 - mae: 0.0042 - val_loss: 1.1576e-04 - val_mae: 0.0053\n",
            "Epoch 435/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4.5071e-05 - mae: 0.0042\n",
            "Epoch 435: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 4.3938e-05 - mae: 0.0042 - val_loss: 1.1571e-04 - val_mae: 0.0053\n",
            "Epoch 436/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.4994e-05 - mae: 0.0042\n",
            "Epoch 436: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.3865e-05 - mae: 0.0042 - val_loss: 1.1566e-04 - val_mae: 0.0053\n",
            "Epoch 437/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.4917e-05 - mae: 0.0042\n",
            "Epoch 437: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.3791e-05 - mae: 0.0042 - val_loss: 1.1561e-04 - val_mae: 0.0053\n",
            "Epoch 438/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.4840e-05 - mae: 0.0042\n",
            "Epoch 438: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.3717e-05 - mae: 0.0042 - val_loss: 1.1557e-04 - val_mae: 0.0053\n",
            "Epoch 439/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.4762e-05 - mae: 0.0042\n",
            "Epoch 439: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.3643e-05 - mae: 0.0042 - val_loss: 1.1552e-04 - val_mae: 0.0053\n",
            "Epoch 440/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.4684e-05 - mae: 0.0042\n",
            "Epoch 440: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.3568e-05 - mae: 0.0042 - val_loss: 1.1548e-04 - val_mae: 0.0053\n",
            "Epoch 441/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.3821e-05 - mae: 0.0042\n",
            "Epoch 441: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 4.3493e-05 - mae: 0.0042 - val_loss: 1.1544e-04 - val_mae: 0.0053\n",
            "Epoch 442/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.3744e-05 - mae: 0.0042\n",
            "Epoch 442: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.3416e-05 - mae: 0.0042 - val_loss: 1.1540e-04 - val_mae: 0.0053\n",
            "Epoch 443/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.4444e-05 - mae: 0.0042\n",
            "Epoch 443: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.3339e-05 - mae: 0.0042 - val_loss: 1.1536e-04 - val_mae: 0.0053\n",
            "Epoch 444/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.4361e-05 - mae: 0.0042\n",
            "Epoch 444: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.3260e-05 - mae: 0.0042 - val_loss: 1.1532e-04 - val_mae: 0.0053\n",
            "Epoch 445/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.4278e-05 - mae: 0.0042\n",
            "Epoch 445: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.3180e-05 - mae: 0.0042 - val_loss: 1.1528e-04 - val_mae: 0.0053\n",
            "Epoch 446/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.4192e-05 - mae: 0.0042\n",
            "Epoch 446: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.3099e-05 - mae: 0.0041 - val_loss: 1.1525e-04 - val_mae: 0.0053\n",
            "Epoch 447/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.3338e-05 - mae: 0.0042\n",
            "Epoch 447: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.3016e-05 - mae: 0.0041 - val_loss: 1.1521e-04 - val_mae: 0.0053\n",
            "Epoch 448/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.3253e-05 - mae: 0.0041\n",
            "Epoch 448: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 4.2932e-05 - mae: 0.0041 - val_loss: 1.1518e-04 - val_mae: 0.0053\n",
            "Epoch 449/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 4.3526e-05 - mae: 0.0041\n",
            "Epoch 449: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 4.2847e-05 - mae: 0.0041 - val_loss: 1.1515e-04 - val_mae: 0.0053\n",
            "Epoch 450/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 4.3437e-05 - mae: 0.0041\n",
            "Epoch 450: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 4.2761e-05 - mae: 0.0041 - val_loss: 1.1513e-04 - val_mae: 0.0053\n",
            "Epoch 451/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 4.3347e-05 - mae: 0.0041\n",
            "Epoch 451: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 4.2673e-05 - mae: 0.0041 - val_loss: 1.1511e-04 - val_mae: 0.0053\n",
            "Epoch 452/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 4.3256e-05 - mae: 0.0041\n",
            "Epoch 452: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 4.2586e-05 - mae: 0.0041 - val_loss: 1.1509e-04 - val_mae: 0.0053\n",
            "Epoch 453/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.3166e-05 - mae: 0.0041\n",
            "Epoch 453: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.2498e-05 - mae: 0.0041 - val_loss: 1.1508e-04 - val_mae: 0.0053\n",
            "Epoch 454/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.3471e-05 - mae: 0.0041\n",
            "Epoch 454: val_loss improved from 0.00012 to 0.00012, saving model to ./best-model.keras\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.2410e-05 - mae: 0.0041 - val_loss: 1.1508e-04 - val_mae: 0.0053\n",
            "Epoch 455/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.3380e-05 - mae: 0.0041\n",
            "Epoch 455: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.2324e-05 - mae: 0.0041 - val_loss: 1.1509e-04 - val_mae: 0.0053\n",
            "Epoch 456/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.2550e-05 - mae: 0.0041\n",
            "Epoch 456: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.2239e-05 - mae: 0.0041 - val_loss: 1.1511e-04 - val_mae: 0.0053\n",
            "Epoch 457/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.3205e-05 - mae: 0.0041\n",
            "Epoch 457: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 4.2157e-05 - mae: 0.0041 - val_loss: 1.1514e-04 - val_mae: 0.0054\n",
            "Epoch 458/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.2733e-05 - mae: 0.0041\n",
            "Epoch 458: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.2078e-05 - mae: 0.0041 - val_loss: 1.1519e-04 - val_mae: 0.0054\n",
            "Epoch 459/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.3043e-05 - mae: 0.0041\n",
            "Epoch 459: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 4.2003e-05 - mae: 0.0041 - val_loss: 1.1525e-04 - val_mae: 0.0054\n",
            "Epoch 460/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.2969e-05 - mae: 0.0041\n",
            "Epoch 460: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.1933e-05 - mae: 0.0041 - val_loss: 1.1533e-04 - val_mae: 0.0054\n",
            "Epoch 461/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.2903e-05 - mae: 0.0041\n",
            "Epoch 461: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 4.1871e-05 - mae: 0.0041 - val_loss: 1.1544e-04 - val_mae: 0.0054\n",
            "Epoch 462/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.2846e-05 - mae: 0.0041\n",
            "Epoch 462: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.1816e-05 - mae: 0.0041 - val_loss: 1.1557e-04 - val_mae: 0.0054\n",
            "Epoch 463/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.2076e-05 - mae: 0.0041\n",
            "Epoch 463: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 4.1772e-05 - mae: 0.0041 - val_loss: 1.1573e-04 - val_mae: 0.0054\n",
            "Epoch 464/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.2384e-05 - mae: 0.0041\n",
            "Epoch 464: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.1741e-05 - mae: 0.0041 - val_loss: 1.1593e-04 - val_mae: 0.0054\n",
            "Epoch 465/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.2747e-05 - mae: 0.0041\n",
            "Epoch 465: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.1726e-05 - mae: 0.0041 - val_loss: 1.1617e-04 - val_mae: 0.0054\n",
            "Epoch 466/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.2371e-05 - mae: 0.0041\n",
            "Epoch 466: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.1731e-05 - mae: 0.0041 - val_loss: 1.1647e-04 - val_mae: 0.0054\n",
            "Epoch 467/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.2779e-05 - mae: 0.0042\n",
            "Epoch 467: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.1761e-05 - mae: 0.0041 - val_loss: 1.1683e-04 - val_mae: 0.0054\n",
            "Epoch 468/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.2841e-05 - mae: 0.0042\n",
            "Epoch 468: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.1824e-05 - mae: 0.0042 - val_loss: 1.1726e-04 - val_mae: 0.0054\n",
            "Epoch 469/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 4.2566e-05 - mae: 0.0042\n",
            "Epoch 469: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 4.1928e-05 - mae: 0.0042 - val_loss: 1.1779e-04 - val_mae: 0.0054\n",
            "Epoch 470/500\n",
            "\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 4.2723e-05 - mae: 0.0042\n",
            "Epoch 470: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 4.2084e-05 - mae: 0.0042 - val_loss: 1.1843e-04 - val_mae: 0.0054\n",
            "Epoch 471/500\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 4.2610e-05 - mae: 0.0042\n",
            "Epoch 471: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 4.2309e-05 - mae: 0.0042 - val_loss: 1.1918e-04 - val_mae: 0.0054\n",
            "Epoch 472/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.3642e-05 - mae: 0.0043\n",
            "Epoch 472: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.2619e-05 - mae: 0.0043 - val_loss: 1.2006e-04 - val_mae: 0.0054\n",
            "Epoch 473/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.4059e-05 - mae: 0.0043\n",
            "Epoch 473: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 4.3034e-05 - mae: 0.0043 - val_loss: 1.2104e-04 - val_mae: 0.0054\n",
            "Epoch 474/500\n",
            "\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.4594e-05 - mae: 0.0044\n",
            "Epoch 474: val_loss did not improve from 0.00012\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.3569e-05 - mae: 0.0044 - val_loss: 1.2202e-04 - val_mae: 0.0054\n",
            "Epoch 474: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраним лучшую модель"
      ],
      "metadata": {
        "id": "9nfwbaNag3lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = load_model(checkpoint_path)\n",
        "best_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "M1UlMPsW1Nb1",
        "outputId": "fd260afb-0c43-4b20-8cb0-e027e9a1eefc"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m7\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m5,120\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,461\u001b[0m (60.40 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,461</span> (60.40 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,153\u001b[0m (20.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,153</span> (20.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m10,308\u001b[0m (40.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,308</span> (40.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeZo5m6XQxdD",
        "outputId": "a78eb3ce-347f-4e06-ff11-d8c3ee30b2dc"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(316, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_t = []\n",
        "y_t = []\n",
        "window = 50\n",
        "\n",
        "for i in range(len(X_test)-window):\n",
        "    X_t.append(X_test[i:i+window])\n",
        "    y_t.append(y_test[i+window])\n",
        "\n",
        "X_t = np.array(X_t)\n",
        "y_t = np.array(y_t)"
      ],
      "metadata": {
        "id": "w6iV4ZWRQUd0"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBERKDp5VGGD",
        "outputId": "0f1e74e7-e769-41f9-9717-26b103ba2ea6"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(266, 50, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = best_model.predict(X_t)\n",
        "inv_predictions = scaler.inverse_transform(predictions)\n",
        "inv_real = scaler.inverse_transform(y_t.reshape(-1, 1))\n",
        "\n",
        "predictions = inv_predictions.reshape(1, -1)[0]\n",
        "real_values = inv_real"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgflgZB7VbyC",
        "outputId": "ba2d03eb-6fad-47fd-b25a-32200e2dac41"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1)\n",
        "ax.plot(predictions, label='prediction')\n",
        "ax.plot(real_values, label='real values')\n",
        "ax.set_ylabel('High, $')\n",
        "ax.set_title('Prediction of toncoin\\'s stock high price', fontsize=16)\n",
        "ax.legend()\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "EgJzCiskVidl",
        "outputId": "7439f157-0641-4a06-dfeb-c8a5839e37d3"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 554,
              "height": 438
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(real_values, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ydws04ihJ6l",
        "outputId": "d075d774-7358-4bea-aac3-a5c422fb4d4e"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9674528385928874"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видно, что данные предсказались очень качественно, о чем говорит коэффициент детерминации близкий к единице. В данной модели я добавил технические индексы, которые обычно используют трейдеры для анализа графиков котировок, для улучшения результата предсказания.\n",
        "\n",
        "Кроме того данный код можно настроить на любую акцию, валюту, крипту, благодаря библиотеке yfinance."
      ],
      "metadata": {
        "id": "7xktti9nhOVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def predict_today():\n",
        "end_time = dt.datetime.now()\n",
        "day_ago = end_time + dt. timedelta(days =- 50)\n",
        "data_today = yf.download('BTC-USD', start=day_ago, end=end_time)\n",
        "data_today ['rsi'] = ta.rsi(data_today.Close, length=15)\n",
        "data_today ['ema_20'] = ta.ema(data_today.Close, length=20)\n",
        "data_today ['ema_50'] = ta.ema(data_today.Close, length=50)\n",
        "del data_today ['Close' ]\n",
        "del data_today ['Adj Close']\n",
        "data_today = data_today.iloc[-1]\n",
        "print(data_today)\n",
        "data_today_scaled = x_scaler.transform(data_today.values. reshape(1, -1))\n",
        "print(data_today_scaled)\n",
        "predict_today = model.predict(data_today_scaled)\n",
        "inversed = y_scaler. inverse_transform(predict_today)\n",
        "print(f'{end_time + dt.timedelta(days=1)} close price will be: {inversed}$')\n",
        "'''"
      ],
      "metadata": {
        "id": "qt9a1BeJWChj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}